{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN-BERT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../img/ganbert.jpg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dados para o GAN-BERT são organizados nos arquivos `labeled.tsv`, `unlabeled.tsv` e `test.tsv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fine_label utterance\n",
      "SUBJ:0 a chilling tale of one of the great crimes of th century france the murder of two rich women by their servants in \n",
      "SUBJ:1 fate brings emma and bret together and they discover shared disdain for clients who collect art to impress others follow the current trend or think only in terms of investment value \n",
      "SUBJ:0 wilco fans will have a great time and the movie should win the band a few new converts too \n",
      "SUBJ:0 functions as both a revealing look at the collaborative process and a timely tongue in cheek profile of the corporate circus that is the recording industry in the current climate of mergers and downsizing \n",
      "SUBJ:0 succeeds very well in its primary aim of making us gasp \n",
      "SUBJ:1 based on frances mayes memoir of the same name \n",
      "SUBJ:0 the main characters are simply named the husband the wife and the kidnapper emphasizing the disappointingly generic nature of the entire effort \n",
      "SUBJ:1 her father invented the world panorama for use by the authorities but was turned down \n",
      "SUBJ:1 knowing that the legend of the temple describes ancient mystical music as the key to unlock its secrets jake enlists the help of samantha sam kincaid an expert musicologist \n"
     ]
    }
   ],
   "source": [
    "!head ../../ganbert_subj/data/subj_un_001/labeled.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fine_label utterance\n",
      "UNK:UNK vile and tacky are the two best adjectives to describe ghost ship\n",
      "UNK:UNK in the meantime the british forces back at the encampment march off to meet the american forces for a grand battle which will rage for hours\n",
      "UNK:UNK netes father becomes bitter and introvert but nete insists that he come to live with her and her family the few weeks he has left\n",
      "UNK:UNK the latest installment in the pokemon canon pokemon ever is surprising less moldy and trite than the last two likely because much of the japanese anime is set in a scenic forest where pokemon graze in peace\n",
      "UNK:UNK a documentary examining the december nd assassination of microsoft ceo bill gates in los angeles and the group of key players seeking to unravel the mystery of his alleged assassin as well as the circumstances surrounding his death\n",
      "UNK:UNK francophiles will snicker knowingly and youll want to slap them\n",
      "UNK:UNK the jokes are sophomoric stereotypes are sprinkled everywhere and the acting ranges from bad to bodacious\n",
      "UNK:UNK this idea has lost its originality and neither star appears very excited at rehashing what was basically a one joke picture\n",
      "UNK:UNK the search takes vir to bombay where he soon regains his memory and finds his real name to be a muslim game marksman named ali and is targed by criminal bigwigs and corrupt government officials whom he used to work for and betrayed him after hiring him to assasinate various underworld criminals and then framed him for the murder of an innocent chief minister\n"
     ]
    }
   ],
   "source": [
    "!head ../../ganbert_subj/data/subj_un_001/unlabeled.tsv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplo de entrada do BERT\n",
    "\n",
    "INFO:tensorflow:*** Example ***\n",
    "\n",
    "INFO:tensorflow:guid: train-SUBJ:1 arrested and imprisoned in a juvenile detention facility leland comes in contact with an aspiring writer and prison teacher pearl madison cheadle \n",
    "\n",
    "INFO:tensorflow:tokens: [CLS] arrested and imprisoned in a juvenile detention facility le ##land comes in contact with an aspiring writer and prison teacher pearl mad ##ison ch ##ead ##le [SEP]\n",
    "\n",
    "INFO:tensorflow:input_ids: 101 3950 1105 8269 1107 170 15031 13826 3695 5837 1931 2502 1107 3232 1114 1126 25850 2432 1105 3315 3218 24837 6340 7614 22572 12393 1513 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    "\n",
    "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    "\n",
    "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
    "\n",
    "INFO:tensorflow:label: SUBJ_1 (id = 2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo BERT utilizado https://storage.googleapis.com/bert_models/2018_10_18/cased_L-12_H-768_A-12.zip"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dados\n",
    "\n",
    "INFO:tensorflow:*** Features ***\n",
    "\n",
    "INFO:tensorflow:  name = input_ids, shape = (64, 64)\n",
    "\n",
    "INFO:tensorflow:  name = input_mask, shape = (64, 64)\n",
    "\n",
    "INFO:tensorflow:  name = is_real_example, shape = (64,)\n",
    "\n",
    "INFO:tensorflow:  name = label_ids, shape = (64,)\n",
    "\n",
    "INFO:tensorflow:  name = label_mask, shape = (64,)\n",
    "\n",
    "INFO:tensorflow:  name = segment_ids, shape = (64, 64)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saída do BERT\n",
    "\n",
    "\n",
    "```\n",
    "tensor([[-0.3124,  0.5256,  0.9981,  ...,  0.9997, -0.7138,  0.9547],\n",
    "        [-0.5034,  0.6236,  0.9995,  ...,  0.9999, -0.1922,  0.9475],\n",
    "        [-0.0393,  0.4882,  0.9965,  ...,  0.9993, -0.9119,  0.9660],\n",
    "        ...,\n",
    "        [-0.0552,  0.4531,  0.9954,  ...,  0.9994, -0.9394,  0.9714],\n",
    "        [-0.5643,  0.5076,  0.9997,  ...,  0.9999, -0.0433,  0.9664],\n",
    "        [-0.2110,  0.4298,  0.9980,  ...,  0.9995, -0.6424,  0.9537]],\n",
    "       device='cuda:0', grad_fn=<TanhBackward0>)\n",
    "torch.Size([64, 768])\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saída do Gerador\n",
    "\n",
    "```\n",
    "tensor([[ 0.2726, -0.0464, -0.2440,  ..., -0.2718,  0.2842, -0.1519],\n",
    "        [ 0.4422, -0.1188, -0.0544,  ..., -0.4002,  0.0767, -0.0866],\n",
    "        [ 0.2127, -0.0400, -0.3291,  ..., -0.3526,  0.3529, -0.2562],\n",
    "        ...,\n",
    "        [ 0.4526, -0.0307, -0.1168,  ..., -0.1448,  0.0499, -0.0420],\n",
    "        [ 0.3388, -0.0700, -0.2178,  ..., -0.1839,  0.3749, -0.0271],\n",
    "        [ 0.2655, -0.0607, -0.1258,  ..., -0.3140,  0.3294, -0.1767]],\n",
    "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
    "torch.Size([64, 768])\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variáveis treináveis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INFO:tensorflow:**** Trainable Variables ****\n",
    "\n",
    "INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (28996, 768), *INIT_FROM_CKPT*\n",
    "\n",
    "INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
    "\n",
    "INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n",
    "\n",
    "INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
    "\n",
    "INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
    "\n",
    "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
    "\n",
    "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
    "\n",
    "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
    "\n",
    "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
    "\n",
    "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
    "\n",
    "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
    "\n",
    "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
    "\n",
    "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
    "\n",
    "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
    "\n",
    "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
    "\n",
    "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
    "\n",
    "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
    "\n",
    "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
    "\n",
    "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
    "\n",
    "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
    "\n",
    "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
    "\n",
    "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
    "\n",
    "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
    "\n",
    "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
    "\n",
    "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
    "\n",
    "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
    "\n",
    "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
    "\n",
    "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
    "\n",
    "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
    "\n",
    "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
    "\n",
    "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
    "\n",
    "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
    "\n",
    "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
    "\n",
    "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
    "\n",
    "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
    "\n",
    "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
    "\n",
    "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
    "\n",
    "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
    "\n",
    "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
    "\n",
    "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
    "\n",
    "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
    "\n",
    "..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------\n",
    "#  Transformer parameters\n",
    "#--------------------------------\n",
    "max_seq_length = 64\n",
    "batch_size = 64\n",
    "\n",
    "#--------------------------------\n",
    "#  GAN-BERT specific parameters\n",
    "#--------------------------------\n",
    "# number of hidden layers in the generator, \n",
    "# each of the size of the output space\n",
    "num_hidden_layers_g = 1; \n",
    "# number of hidden layers in the discriminator, \n",
    "# each of the size of the input space\n",
    "num_hidden_layers_d = 1; \n",
    "# size of the generator's input noisy vectors\n",
    "noise_size = 100\n",
    "# dropout to be applied to discriminator's input vectors\n",
    "out_dropout_rate = 0.2\n",
    "\n",
    "# Replicate labeled data to balance poorly represented datasets, \n",
    "# e.g., less than 1% of labeled material\n",
    "apply_balance = True\n",
    "\n",
    "#--------------------------------\n",
    "#  Optimization parameters\n",
    "#--------------------------------\n",
    "learning_rate_discriminator = 5e-5\n",
    "learning_rate_generator = 5e-5\n",
    "epsilon = 1e-8\n",
    "num_train_epochs = 10\n",
    "multi_gpu = True\n",
    "# Scheduler\n",
    "apply_scheduler = False\n",
    "warmup_proportion = 0.1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gerador\n",
    "\n",
    "* Camadas linerares (1 camada, 512 neurônios)\n",
    "* Função de ativação leakyReLU (0.2)\n",
    "* Dropout (0.1)\n",
    "* Entrada noise (100)\n",
    "* Saída (512)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminador\n",
    "\n",
    "* Camadas linerares (1 camada + 1 linear/softmax, 512 neurônios)\n",
    "* Função de ativação leakyReLU (0.2)\n",
    "* Dropout (0.1)\n",
    "* Entrada (512)\n",
    "* Saída (2 + 1 fake)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN-TEXTGEN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../img/gan-textgen.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dados para o GAN-TEXTGEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tthe problem is that the movie has no idea of it is serious or not . \n",
      "1\ton an out of control train holding hostages and high-tech bio-weapons agent kristoff ( van damme ) becomes a one man army to derail the terrorists and save the lives of everyone on board ! \n",
      "0\tparker cannot sustain the buoyant energy level of the film's city beginnings into its country conclusion\n",
      "1\temory , a former governor of his tribe , is reunited with his son larry , via the help of a friend , sky montgomery , who invites larry to travel from the old pueblo to the new \" big city \" to join his father at a photo-art exhibition hosted by sky . \n",
      "0\tthis is cool , slick stuff , ready to quench the thirst of an audience that misses the summer blockbusters . \n",
      "1\trio danisworo ( marcellius siahaan ) is a rigid \" all about business \" young profesional . \n",
      "0\tit's fun , but the code-talk will fly right over everyone's head\n",
      "1\twhile treating a homicide detective for smoking , hypnotherapist michael strother has a telepathic vision of a young girl floating beneath the surface of a stream . \n",
      "0\tit's a lovely , eerie film that casts an odd , rapt spell . \n",
      "1\tbut the day he does , he pulls one last detention duty with the toughest kids in the school . \n"
     ]
    }
   ],
   "source": [
    "!head ../data/subj/train_un_001.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNK\tdue to unfortunate circumstances he is forced to flee his former brothers in arms . \n",
      "UNK\tbut all is not smooth in the rockies , as their relationship accelerates - cultural differences , family issues , former loves and life-altering challenges threaten to shake things up . \n",
      "UNK\tnot only are the film's sopranos gags incredibly dated and unfunny , they also demonstrate how desperate the makers of this 'we're -doing-it-for -the-cash' sequel were . \n",
      "UNK\tan interesting , if not entirely successful , biography of two extraordinary personalities . \n",
      "UNK\tlos angeles' little tokyo's foremost studio photographer , miyatake smuggled a lens and film holder into the u . s . wwii camp he was incarcerated in and captured life behind barbed wire with a makeshift camera made of scrap wood . \n",
      "UNK\tfeels less like a cousin to blade runner than like a bottom-feeder sequel in the escape from new york series . \n",
      "UNK\toffers a gentle summer fantasy for both grown-ups and little ones . \n",
      "UNK\tcrush could be the worst film a man has made about women since valley of the dolls . \n",
      "UNK\teveryone connected to this movie seems to be part of an insider clique , which tends to breed formulaic films rather than fresh ones . \n",
      "UNK\tconnie sumner has a loving husband , a beautiful home , and a wonderful son , but she wants more . \n"
     ]
    }
   ],
   "source": [
    "!tail ../data/subj/train_un_001.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saída do pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "tensor([[    1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
    "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
    "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
    "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
    "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
    "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
    "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
    "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
    "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
    "             1,     1,     1,     1,     1,     1,     1,     1,  2181,     7,\n",
    "           655,   540,    17,    65,    13,    78,   141,   169,    86,   641,\n",
    "            70,     6,    11,   104,  2491,    14,    76,     2],\n",
    "            ...\n",
    "shape = torch.Size([8, 118])\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saída do gerador"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "tensor([[ 4090, 11000,  7578,  5285,  7228, 19811,  7131, 15849, 14560, 10865,\n",
    "          2648, 12967,    68,  1394, 11009, 18530,  2722, 18712,  8821,   420,\n",
    "         13117,  2491,   217, 16313, 15592,  9648,  4268,  9140,  2084, 17412,\n",
    "         20138,  1730, 16664,  4659,  6740, 18687,  3150,  8856,  5743,  1525,\n",
    "          5393,  5393,  4664, 14332,  4017, 17118, 21387,  3703,  7443, 19710,\n",
    "          3823,  7529, 11767, 16162, 10091,   783,  4891, 11345, 16871, 13877,\n",
    "         13877,  1578, 14021, 20042,  8622,  7886,  8943,   600,  9484,  3539,\n",
    "         14814, 12075,  6244, 13223,  4674, 10574, 18444, 20211, 21027,  4918,\n",
    "          8894,  3160, 17645, 10373, 19883,  3757, 17242, 20366, 18851, 15860,\n",
    "         11838,   475, 12367,  2487, 20663,  2324,  1509,  3673,  6288, 19292,\n",
    "         12287,  9455, 16928,  2197, 11774, 16742,  8020, 12560, 12165,  5217,\n",
    "          3982, 13858,  4845, 19026, 21232, 16566,  1803, 18652],\n",
    "shape = torch.Size([8, 118])\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print_each_n_step = 50\n",
    "num_train_epochs = 10\n",
    "noise_size = 100\n",
    "max_seq_length = 200\n",
    "batch_size = 8\n",
    "epsilon = 1e-8\n",
    "word2vec_len = 300"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gerador\n",
    "\n",
    "* Camadas GRU (1 camada, 64 neurônios)\n",
    "* Sem função de ativação\n",
    "* Dropout (0.1)\n",
    "* Entreda noise (100)\n",
    "* Saída (29405)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminador\n",
    "\n",
    "* 1 camada LSTM (+ 1 linear/softmax), 64\n",
    "* Sem função de ativação\n",
    "* Dropout (0.1)\n",
    "* Embedding do texto na entrada com vetores word2vec prontos\n",
    "* Entrada (300)\n",
    "* Saída (2 + 1 fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mestrado",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
