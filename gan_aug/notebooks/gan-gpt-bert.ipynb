{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../core')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/mestrado/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, AutoModelForCausalLM\n",
    "\n",
    "import time\n",
    "from typing import Dict, List\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from data_utils import format_time, save_stats\n",
    "from dataloader import create_bert_dataloaders\n",
    "from dataset_loader import dataset_loader\n",
    "from torch.utils.data import DataLoader\n",
    "from models.bert_discriminator import BERTDiscriminator, model_name\n",
    "from transformers import AutoTokenizer\n",
    "from util.early_stopping import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'aclImdb_001'\n",
    "train_sentences, train_labels, _, _ = dataset_loader.load_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n",
      "1. A typical romp through Cheech and Chong's reality which includes drugs, singing, more drugs, cars and driving, even more drugs, Pee Wee, aliens, gasoline, laundry, stand up comedy, surprisingly more drugs and SPACE COKE !!. It is not as coherent or plausible as Up in Smoke but it still is incredibly funny, without becoming as strange as Nice Dreams. There are some classic scenes, which include the opening scene where they get some gas for their car and the drive to work. Also funny is Cheech's song (Mexican-Americans) and Chong's follow up song. Another notable scene is the welfare office scene with Jones (human noise machine), from the Police Academy series, and the old laughing man. All in all, this is a great follow up to Up in Smoke and is quite watchable when sober or not.<br /><br />-Celluloid Rehab\n",
      "2. This film seems to be well remembered as the time Tom & Jerry signed a peace treaty. Things are idyllic for a time but, predictably, it goes sour. Probably the most memorable moment was the endless fight involving a pipe, a frying pan, and a baseball bat that the two plus Butch the dog engage in at the beginning and end of the short. I enjoyed one a bunch and you should try to catch it on Cartoon Network.\n",
      "3. This movie is bufoonery! and I loved it! The \"dragon lord\" (Jacky Chan) and his buddy, \"cowboy\", totally made the movie fun, meaningful, and just plain silly. The movie is a rare blend of a good vs. evil fight and (somehow) the wonders and fun that is growing up. Long Shao Ye takes the viewer through the daily activities of the young \"dragon lord\" (so named because he is the son of a wealthy family) and \"cowboy\", which include implementing clever, elaborate ways to escape studying (with the help of the entire household, including the tutor), competing in rather boyish (and idiotically interesting) ways to gain the affection of a local girl, competing in \"soccer\" (you will see what i mean) and the list goes on. Somehow they find themselves in the midst of a fight to save the a shipment of valuable antiques and the lives of several people.<br /><br />The movie has its serious moments. But they do not depress, but rather inspire. The playfulness of the boys are not lost in this exchange, but is actually employed against evil. What I really loved about this movie is how it ends. Not the typical confrontation (which in itself was awesome), but well, you'll see. Let me just say it truly captures the spirit of the movie.<br /><br />silly, witty, meaningful, and nostalgic. great movie.\n",
      "4. A meteor drops from the sky and reawakens a plesiosaur that long ago used to terrorize the area around Crater Lake . As the monster eats the locals they try and find away of killing the monster.<br /><br />Recent attempts at sending up old horror and science fiction films like Lost Skeleton of Cadavra and Alien Trespass are kind of rendered moot when you have films like Crater Lake Monster available for screening. It's the sort of film that those films spoof and send up only this is the real deal. Its everything those films try to be only with out the tongue in cheek and its so much more fun because of it. This is a real drive-in sort of film that had the unfortunate luck of coming just as Star Wars changed the way we look at special effects. The monster, a mix of stop motion and a life size head, is a charmingly quaint little beast. The filmmakers spoil the audience with frequent shots of the monster and its mayhem. Sure its clear that its all fake, but isn't movies about suspension of disbelief? Actually I think its about really cool monsters, which this has.<br /><br />I like this movie in a low budget drive in sort of a way. If you want a real authentic drive in monster movie look no farther. This would be perfect for a double or triple feature with similar lake monster films (Boggy Creek etc.)\n",
      "Negative\n",
      "1. <br /><br />I am a big-time horror/sci-fi fan regardless of budget, but after watching countless horror movies late night on cable and video, this has to be the worst of all movies. With bloody special effects (what looked like a roast covered in fake blood or ketchup that kept being shown over and over again) and people running around screaming from left, then to right, then back again. It should have stayed with the beginning convenience store scene and stopped there and been 15 minutes. Instead, it is dragged out very long. It is very, very x5 low budget. Many scenes were way, way too long. Narrator sounded very amateurish like a random person out of junior high was talking. This is the only movie to rate lower in my opinion than Manos, Red Zone Cuba, Benji,and Godzilla vs. megalon despite their higher budgets. 10 snoozes, try to stay awake through whole movie in one setting or better yet, avoid it like you would an undead brain-eating mob. The Why-Did-I-Ever-See-This-Piece-Of-Zombie-Dung-Blues. Epitome of nauseatingly bad made movies etc..ad infinitum. -infinity/10\n",
      "2. I chose to see this movie because it got a good score here on IMDb. But a lot of people either have really poor taste or someone's been fixing the score.<br /><br />Either way it was a real disappointment. The movie is exactly as stupid and far fetched as the title would suggest. There really is no reason to give a summary of the plot - but here goes: it felt like someone had been thinking: \"Wouldn't it be cool to make a movie where there were snakes on a plane? And then the snakes for some reason would go crazy and start biting and stuff?!?\" And that's about it! The plot is thin and unoriginal. The snakes are bad CGI (but it makes sense to cut corners on a movie that no one in their right mind will recommend to anyone!). The acting is poor, and all people are unbelievable stereo types.<br /><br />To sum it up: It's one of the worst movies I've ever seen - stay away!\n",
      "3. The movie confuses religious ethics and ideals so much that it fails to create coherent argument against the death penalty on any level. By presenting the lawful execution of a convicted murder as the catalyst for the apocalyptic end of mankind the movie elevates a parent killer to the status of martyr for Christ. Somehow, according to the plot, god is outraged that society has chosen to rid it's self of a fanatic who killed his own parents by starting them on fire while they slept defenselessly in their beds. Yet this same god has no indignation for the acts of the killer. The lead character, an nonreligious pregnant suicidal woman, ultimately gives her own life in a defiant but implausible attempt to unsuccessfully save this convicted killer. In other threads of the underdeveloped plot Jesus comes back as a powerless and frustrated vagabond to symbolically unleash the wrath of God. The modern lackluster incarnation of Christ not just dehumanizes him but mocks the messianic ideal of all religions as well. He is unable to affect humanity for good and unemotionally skates the edges of life waiting for mankind to destroy it's self. Meanwhile, with little help from Jesus the mentally unstable pregnant woman finds herself with the ability to reincarnate herself into her newly born soulless child which somehow saves all of mankind from the wrath of the almighty. I also interpreted that as a statement in support of abortion on some levels. This movie which attempts to weave many religious themes into a thriller fails to make any religious point that I could clearly interpret except to mock people's beliefs. It raises many questions that it never even attempts to answer. It disregards the religious values of its audience while attempting to portray an asinine version of their fulfillment. Silly\n",
      "4. I actually saw China O'Brien II before I ever saw the original China O'Brien. And I have to say that the first incarnation is actually worse. But: worse = funnier! And funnier = better. If you're a bad movie fan like I am, this is great material. If, however, you are looking for any sort of meaningful plot, acting ability, or movie-making skill, this is best avoided. The best part is how they filmed all the fighting sequences in stuttering fast-forward. Hilariously bad. See it for a laugh, see it for mindless entertainment, but whatever you do, see it for free on TV.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "positive_sentences = [sentence for sentence, label in zip(train_sentences, train_labels) if label == '1']\n",
    "negative_sentences = [sentence for sentence, label in zip(train_sentences, train_labels) if label == '0']\n",
    "print('Positive')\n",
    "for i in range(1, 5):\n",
    "    sentence = random.choice(positive_sentences)\n",
    "    print(f'{i}. {sentence}')\n",
    "\n",
    "print('Negative')\n",
    "for i in range(1, 5):\n",
    "    sentence = random.choice(negative_sentences)\n",
    "    print(f'{i}. {sentence}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_tokenizer = GPT2Tokenizer.from_pretrained('gpt2', padding_side='left')\n",
    "generator = AutoModelForCausalLM.from_pretrained('gpt2')\n",
    "gpt_tokenizer.pad_token = gpt_tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SUBJ Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# objetive_prompt = '''Here are 3 examples of objetive moview reviews:\n",
    "\n",
    "# 1. it is a study of dark forces lurking in the lives of teenagers today . \\n\n",
    "# 2. during the course of the story we also learn that his father died at age 40 ; and now , as jones approaches his 40th birthday , he suffers from \" survivor\\'s guilt . \" \\n\n",
    "# 3. '''\n",
    "\n",
    "# subjective_prompt = '''Here are 3 examples of subjetive moview reviews:\n",
    "\n",
    "# 1. few films seem so wise and knowing about the fact of age and the approach of the end . \\n\n",
    "# 2. fessenden continues to do interesting work , and it would be nice to see what he could make with a decent budget . but the problem with wendigo , for all its effective moments , isn't really one of resources . \\n\n",
    "# 3. '''\n",
    "\n",
    "prompt = '''Here are exactly 5 movie reviews written in movie forums, some are objective and some are subjective:\n",
    "\n",
    "1. has a shambling charm . . . a cheerfully inconsequential diversion . \\n\n",
    "\n",
    "2. as violent , profane and exploitative as the most offensive action flick you've ever seen . \\n\n",
    "\n",
    "3. she is intrigued by his knowledge of shakespeare , manner of living and the fifteen perfectly organized bags beneath his bench . \\n\n",
    "\n",
    "4. when mr . hundert tells us in his narration that 'this is a story without surprises , ' we nod in agreement . \\n\n",
    "\n",
    "5.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AclImdb Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# positive_prompt = \"Here are 3 positive movie review from IMDB website written in a user post:\\n 1. For a movie that gets no respect there sure are a lot of memorable quotes listed for this gem. Imagine a movie where Joe Piscopo is actually funny! Maureen Stapleton is a scene stealer. The Moroni character is an absolute scream. Watch for Alan \\\"The Skipper\\\" Hale jr. as a police Sgt\\n 2. A solid, if unremarkable film. Matthau, as Einstein, was wonderful. My favorite part, and the only thing that would make me go out of my way to see this again, was the wonderful scene with the physicists playing badmitton, I loved the sweaters and the conversation while they waited for Robbins to retrieve the birdie.\\n 3. \"\n",
    "# negative_prompt = \"Here are 3 negative movie review from IMDB website written in a user post:\\n 1. Wow! I remember so many awful films that loosely revolved around high school from the early 1980s. They usually had someincredibly strained plot and lots of 27 year old actors pretending to be students. As I watched this film I felt a little of the nostalgia of growing up in the 1980s. However, then I find out that this film was made in 1989? Say what! Well, the nostalgia factor ends right there, this is just bad. The plot has the city preparing to close a high school and threatening to bus all of the students to inner city high schools. Which is odd, in that the students at this school are both wealthy and abundant. In fact, the main character lives in a mansion. Makes you wonder how they cannot find money to keep this school alive, have they never heard of property taxes. Oh, but here is the kicker. The school board says that they will keep the school alive, if the students can raise $200,000. So the seniors go about doing this. Hmmm, you raise $200,000 but instead of saving that for college, you put it towards saving the high school that you are a Senior in? And why exactly would they close an overpopulated school before the year is out? And...ahh forget it, this film was stupid and made in 1989!?\\n 2. What was Steven Seagal thinking? I mean firstly I love Seagal. I love all his movies up to the mid 2000s. His early stuff is some of the best in the genre. This however does not live up to its excellent name. Attack Force (with protagonist Marshall Lawson {Seagal}) would be expected to be a mindless action movie with Seagal in typical one-liner ass kicking form. However, what we get is a crime mystery, bordering on a political thriller with little or no action. Seagal is always in shadows because of his weight. I could not follow this story. There\\'s people who mutate to superhumans when they take a drug. What happened in this movie. The dubbing of Seagal is a disgrace, a shambles and a shame. Why dub the man? The story is terrible. This got a 2/10 from me because of the scene where Seagal asks for backup despite having an army with him, and an hilarious fight scene where seagal swings his hands like a girl facing the camera! \\\"Revenge is a two way street\\\" seagal says in this movie...well forget revenge Steven, you need redemption!\\n 3. \"\n",
    "\n",
    "positive_prompt = '''Here are exactly 5 movie reviews from IMDB, these are positive review written by users:\n",
    "\n",
    "1. Meryl Streep is excellent in her nuanced and stoic performance as the infamous Lindy Chamberlain who was accused and tried for allegedly killing her own baby Azaria Chamberlain and using her alibi of ravenous dingoes as her defense. Based on the book \"Evil Angels\" and titled so in its Australian release, A CRY IN THE DARK is an ugly film to watch. It presents a scenario that's all too real for us in America: the witch-hunt against a person deemed an easy target.\n",
    "2. *some spoilers*<br /><br />I was pleasantly surprised to find the harsh criticisms (acting, dated dialogue, unclear storyline) unfounded. Belafonte is great as a Brandoesque, menacing, swearing spirit who must earn his wings but is realistically ill-equipped from his past life to do so. He learns too late how empty his hustling, materialistic life was without love. Mostel is likewise great as an anguished man with his dying wife Fanny.\n",
    "3. This is not \"so bad that it is good,\" it is purely good! For those who don't understand why, you have the intellect of a four year old (in response to a certain comment...) Anyways, Killer Tomatoes Eat France is a parody of itself, a parody of you, and a parody of me. It is the single most genius text in cinematic history. I have it and the three prequels sitting on my DVD rack next to Herzog and Kurosawa. It embodies the recognition of absurdity and undermines all that you or me call standard.\n",
    "4. Fabulous, fantastic, probably Disney's best musical adventure. I have loved this film for over 35 years because it is so imaginative, clever and fun. Even despite the silly \"flying bed\" scenes, the other scenes and dialog are magical and funny. Could they have picked anyone better than Angela Lansbury to play Eglantine? I cannot think of anyone more suited to the role. Remaking this classic would be as stupid as remaking Mary Poppins.\n",
    "5.'''\n",
    "\n",
    "negative_prompt = '''Here are exactly 5 movie reviews from IMDB, these are negative review written by users:\n",
    "\n",
    "1. I am not a big fan of horror films, and have only seen a handful of them (and none of the \"Halloween\"s or \"Friday the Thirteenth\"s) - but I can appreciate a frightening horror film not because of gore. And I'm pretty sure this isn't scary.\n",
    "2. Or \"Marlowe At Sea\". Yet another ridiculously overrated old film with Bogey. Quite talky, too. Bogey basically plays the same character as in the Marlow films; always in control of a situation, never nervous - no matter how dangerous a situation, calls women \"slim\" and \"dames\" and other such nonsense, is the only \"real male\" i.e. alpha male in the movie (the only other alpha male male being the head of Gestapo - but he is only a fat alpha male male), and - naturally - every attractive young woman who comes his way cannot resist his charms and wants his penis within hours of their initial introduction. The character clichés are all here.\n",
    "3. This installment of Masters of Horror was terrible. Apparently, Mr. Carpenter needs to learn a thing or two about pacing and decent, plausible dialog. There were times when I literally shouted at the TV for something to happen. Maybe he thinks he building suspense, but Carpenter needs to trim back that overdone, over-simplified musical score of his (or his son's) and advance the action a little bit. How many times did the girl say, \"Oh no, I can't have this baby!\" and \"Oh, no here it comes\"?\n",
    "4. Cradle of Fear<br /><br />This isn't a movie where intricate delicate little narrative nuances occupy our attention. This is not a film where the special effects are supposed to leave us slack-jacked uttering that sense of whoa. What it is though is a slice of lo-fi goth horror which leaves little to the imagination, created in the eyes of the director, Alex Chandon, as \"a throwback to sleazy '70s and '80s horror\".\n",
    "5.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpdesk Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = \"Here is an example of helpdesk emails texts about one of the topics General Inquiry, Human Resources, Billing and Payments, Sales and Pre-Sales, IT Support, Customer Service, Product Support, Returns and Exchanges, Service Outages and Maintenance or Technical Support: \\n\\n\"\n",
    "prompt = '''Here are 3 examples of helpdesk emails texts about one of the topics General Inquiry, Human Resources, Billing and Payments, Sales and Pre-Sales, IT Support, Customer Service, Product Support, Returns and Exchanges, Service Outages and Maintenance or Technical Support:\n",
    "\n",
    "1. Sehr geehrtes Support-Team des Tech Online Stores,\\n\\nich interessiere mich für den Kauf eines MacBook Air M1 und hätte gerne detaillierte Spezifikationen sowie Informationen zu den verfügbaren Anpassungsoptionen. Könnten Sie mir bitte diese Informationen zur Verfügung stellen?\\n\\nVielen Dank für Ihre Unterstützung.\\n\\nMit freundlichen Grüßen,\\n<name>\n",
    "2. Le client signale des déconnexions fréquentes et des plantages lors des réunions vidéo utilisant Zoom 5.11.0. Veuillez enquêter. Merci.\n",
    "3. \n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turkish Product Reviews Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_prompt = '''Here are 3 examples of positive product reviews in turkish:\n",
    "\n",
    "1. aldığıma pişman degilim açıklamada bahsedildiği gibi  içiniz rahat alabilirsiniz\n",
    "2. açılırken tutukluk yapabiliyor ama sağlam, işe yarar bir ürün.\n",
    "3. '''\n",
    "negative_prompt = '''Here are 3 examples of negative product reviews in turkish:\n",
    "\n",
    "1. ayakkabı tabanını gereğinden fazla yükseltiyor. eğer ayakkabı ayağınıza büyük geliyorsa tam aradığınız ürün. yarardan çok zararını gördüm diyebilirim, günlük kullandığım ayakkabıları rahat giyemiyorum artık.\n",
    "2. bez siparişimiz, her zaman ertesi gün elimize ulaşıyor, bu konuda sıkıntı yok. ancak aylardır kullandığımız ve hiç sorun yaşamadığımız 5 numara prima'nın yeni içeriğini hiç beğenmedik. çocukta ileri derecede pişik yaptı. sanırım bez markasını deiğiştirme vakti geldi.\n",
    "3. '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MTOD (th) Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''Here are 4 examples of sentences in thailandese about \"alarm\", \"reminder\" or \"weather\":\n",
    "\n",
    "1. หยุดนาฬิกาปลุก\n",
    "2. ความชื้นของวันนี้คืออะไร?\n",
    "3. ปิดเตือนความจำทั้งหมดสำหรับสุดสัปดาห์นี้\n",
    "4. '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "# batch_input = [prompt]\n",
    "batch_input = [positive_prompt, negative_prompt]\n",
    "# batch_input = [subjective_prompt, objetive_prompt]\n",
    "encoded_input = gpt_tokenizer(batch_input, return_tensors='pt', padding=True)\n",
    "output = generator.generate(**encoded_input, temperature=0.9, do_sample=True, max_new_tokens=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>Here are exactly 5 movie reviews from IMDB, these are positive review written by users:\\n\\n1. Meryl Streep is excellent in her nuanced and stoic performance as the infamous Lindy Chamberlain who was accused and tried for allegedly killing her own baby Azaria Chamberlain and using her alibi of ravenous dingoes as her defense. Based on the book \"Evil Angels\" and titled so in its Australian release, A CRY IN THE DARK is an ugly film to watch. It presents a scenario that\\'s all too real for us in America: the witch-hunt against a person deemed an easy target.\\n2. *some spoilers*<br /><br />I was pleasantly surprised to find the harsh criticisms (acting, dated dialogue, unclear storyline) unfounded. Belafonte is great as a Brandoesque, menacing, swearing spirit who must earn his wings but is realistically ill-equipped from his past life to do so. He learns too late how empty his hustling, materialistic life was without love. Mostel is likewise great as an anguished man with his dying wife Fanny.\\n3. This is not \"so bad that it is good,\" it is purely good! For those who don\\'t understand why, you have the intellect of a four year old (in response to a certain comment...) Anyways, Killer Tomatoes Eat France is a parody of itself, a parody of you, and a parody of me. It is the single most genius text in cinematic history. I have it and the three prequels sitting on my DVD rack next to Herzog and Kurosawa. It embodies the recognition of absurdity and undermines all that you or me call standard.\\n4. Fabulous, fantastic, probably Disney\\'s best musical adventure. I have loved this film for over 35 years because it is so imaginative, clever and fun. Even despite the silly \"flying bed\" scenes, the other scenes and dialog are magical and funny. Could they have picked anyone better than Angela Lansbury to play Eglantine? I cannot think of anyone more suited to the role. Remaking this classic would be as stupid as remaking Mary Poppins.\\n5. A master of acting and directing, the \"Hollywood\" has been a big hit with audiences from Europe to America, and the films that I have seen of this era, are so well described to help it stay on the \"fun roll\" you are on to.\\n6. A genius film about the future that will last more than 2 hours. It is a masterpiece, it is the story of our present, our youth, our future.\\n7. I had no idea what to make of this one. I saw the one at the cinema festival, and saw it for free, and I liked it. Here\\'s a review:\\nI have to admit I had an even lighter reaction to this one than I did when I was browsing the internet. I am a very good viewer and I enjoyed the film at the time, and now it is in the hands of many more people that will be watching it! One thing I\\'ve noticed has been a change in the way I viewed this movie. On the one hand, it was not an excellent film. That is, until I watched it for free! The whole \"I\\'m a bad girl\" thing has been replaced by its own version of a little something that is fun for most people in the audience. These days, the \"I need money\" thing only gets to a certain extent, and now I get to see the kind of people who will give up their hard-earned money when they find out they need it. The movie is fun that I watched, because it is so entertaining, and because you get to think this is all about you-the \"adult\", the \"papa\" and the \"girl\". It also has a lot of fun for so many people with little to no knowledge about what they think or do in life. I really enjoy watching this to its fullest and I could not be more proud!\\nAnd there it is. An example of how bad is the film that is so widely recognized today',\n",
       " 'Here are exactly 5 movie reviews from IMDB, these are negative review written by users:\\n\\n1. I am not a big fan of horror films, and have only seen a handful of them (and none of the \"Halloween\"s or \"Friday the Thirteenth\"s) - but I can appreciate a frightening horror film not because of gore. And I\\'m pretty sure this isn\\'t scary.\\n2. Or \"Marlowe At Sea\". Yet another ridiculously overrated old film with Bogey. Quite talky, too. Bogey basically plays the same character as in the Marlow films; always in control of a situation, never nervous - no matter how dangerous a situation, calls women \"slim\" and \"dames\" and other such nonsense, is the only \"real male\" i.e. alpha male in the movie (the only other alpha male male being the head of Gestapo - but he is only a fat alpha male male), and - naturally - every attractive young woman who comes his way cannot resist his charms and wants his penis within hours of their initial introduction. The character clichés are all here.\\n3. This installment of Masters of Horror was terrible. Apparently, Mr. Carpenter needs to learn a thing or two about pacing and decent, plausible dialog. There were times when I literally shouted at the TV for something to happen. Maybe he thinks he building suspense, but Carpenter needs to trim back that overdone, over-simplified musical score of his (or his son\\'s) and advance the action a little bit. How many times did the girl say, \"Oh no, I can\\'t have this baby!\" and \"Oh, no here it comes\"?\\n4. Cradle of Fear<br /><br />This isn\\'t a movie where intricate delicate little narrative nuances occupy our attention. This is not a film where the special effects are supposed to leave us slack-jacked uttering that sense of whoa. What it is though is a slice of lo-fi goth horror which leaves little to the imagination, created in the eyes of the director, Alex Chandon, as \"a throwback to sleazy \\'70s and \\'80s horror\".\\n5. And then there\\'s the whole \"I\\'m not a big fan of the genre and I think it is completely terrible\" part. We know from the first scene when she is told that she is \"too dangerous\" to work at her job on Saturdays. Her friends and family say it doesn\\'t work, and she\\'s not going anywhere. I don\\'t think Alex would have minded making an action movie in which an old man gets mad at her for being so bad at it. But this movie doesn\\'t. It doesn\\'t want the audience to see it as \"a good thing\", even though it is. (And, of course, it doesn\\'t want the audience to see it as \"silly\". It wants this as \"a good thing\" somehow: a really bad thing.) There is only one scene where a man is able to take off his coat, and it\\'s in this scene where he takes off his coat, where this guy has some sort of vision of where is he, and it\\'s the right thing to do. But this is a scene where you don\\'t realize this \"something\" is bad, and you don\\'t even notice that there is a man in his coat, and it\\'s that the scene doesn\\'t take place on Saturday Morning. It is all over, and this is something that can only be accomplished with good directorial direction.\\n 6. This is a very dark, and very dark movie. It\\'s got a strong female protagonist, a villain that has no other character than what he or she is, and yet still has to have a heart of gold, something that is not only true in that setting, but that is a pretty significant element of the whole experience. This is an excellent movie.<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_tokenizer.batch_decode(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_each_n_step = 50\n",
    "num_train_epochs = 50\n",
    "noise_size = 1\n",
    "batch_size = 8\n",
    "epsilon = 1e-8\n",
    "initial_temp = 1.0\n",
    "anneal_rate = 0.95\n",
    "min_temp = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Device setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS backend\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.backends.mps.is_available():\n",
    "    print('Using MPS backend')\n",
    "    device = torch.device('mps')\n",
    "elif torch.cuda.is_available():\n",
    "    # Tell PyTorch to use the GPU.\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using dataset aclImdb_001\n",
      "GPT2LMHeadModel(\n",
      "  (transformer): GPT2Model(\n",
      "    (wte): Embedding(50257, 768)\n",
      "    (wpe): Embedding(1024, 768)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-11): 12 x GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D(nf=2304, nx=768)\n",
      "          (c_proj): Conv1D(nf=768, nx=768)\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D(nf=3072, nx=768)\n",
      "          (c_proj): Conv1D(nf=768, nx=3072)\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n",
      "generator parameters: 124439808\n",
      "BERTDiscriminator(\n",
      "  (transformer): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSdpaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (input_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (logit): Linear(in_features=768, out_features=3, bias=True)\n",
      "  (softmax): Softmax(dim=-1)\n",
      ")\n",
      "discriminator parameters: 178446339\n"
     ]
    }
   ],
   "source": [
    "labels = dataset_loader.get_labels(dataset)\n",
    "\n",
    "train_dataloader, test_dataloader, seq_size = create_bert_dataloaders(dataset, batch_size=batch_size, device=device, tokenizer=tokenizer)\n",
    "\n",
    "# Models\n",
    "discriminator = BERTDiscriminator(1, seq_size, device, num_labels=len(labels))\n",
    "\n",
    "print(generator)\n",
    "print('generator parameters: ' + str(sum(p.numel() for p in generator.parameters() if p.requires_grad)))\n",
    "print(discriminator)\n",
    "print('discriminator parameters: ' + str(sum(p.numel() for p in discriminator.parameters() if p.requires_grad)))\n",
    "\n",
    "generator.to(device)\n",
    "discriminator.to(device)\n",
    "if torch.cuda.is_available():\n",
    "    generator.cuda()\n",
    "    discriminator.cuda()\n",
    "\n",
    "# Training\n",
    "training_stats = []\n",
    "\n",
    "g_vars = [v for v in generator.parameters()]\n",
    "d_vars = [v for v in discriminator.parameters()]\n",
    "\n",
    "gen_optimizer = torch.optim.AdamW(g_vars, lr=5e-5)\n",
    "dis_optimizer = torch.optim.AdamW(d_vars, lr=5e-5)\n",
    "\n",
    "early_stopping = EarlyStopping(patience=5, min_delta=0.001, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to generate fake examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/mestrado/lib/python3.11/site-packages/transformers/pytorch_utils.py:337: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[' This is the first film that I have not seen in a movie review. I am not a fan of reviews, so I can\\'t comment on the reviews here. I am very happy with it.\\n6. It has been said that the most memorable moment of the movie is when a man is shot dead by a mob of people, who will have been so horrified by the crime that they will have jumped from the car and run away. This is a very interesting scene. It is a very sad scene, and I am not sure when it started, but it was very funny at the time. The movie is, and will remain, a story about the life of a man who has been shot in the head.\\n7. There is no good way to describe it. The only way to describe it is that this is a movie that should be watched. It is the most entertaining and most beautiful movie ever made. It is the first of its kind.\\n8. The final part of the film is a beautiful, beautiful scene. It is a beautiful, beautiful movie.\\n9. The last scene is the film that I think most people will remember. It is the last scene that is true to the story of the man who shot the man. It is the final scene that is true to the story of the man who shot the man.\\n10. I am not sure how to describe this movie. I have seen it twice. It was in the American release of \"The Lion King\" and it is in the American release of \"The Jungle Book\" and it is in the American release of \"The Jungle Book 2.\" It is in the American release of \"The Lion King\" and it is in the American release of \"The Jungle Book 2.\" The last scene is the film that I think most people will remember. It is the last scene that is true to the story of the man who shot the man. It is the final scene that is true to the',\n",
       " ' I was expecting something like this in the first place. I was expecting a very dark, dark, dark, dark, dark, dark, and the movie looked like it could be called \"the first of its kind\" - in fact, you\\'re probably thinking, \"What the hell, what did the movie have to do with this?\" Well, it was. I mean, it\\'s not even a horror movie, right? But it\\'s not scary. It\\'s scary because it\\'s a thriller. That\\'s all. This is a great movie, it\\'s a great movie, it\\'s a wonderful movie, and I\\'m still gonna be waiting for the next one, but this is not the last one.\\n\\n\\n***\\n\\n\\nIf you\\'re looking for something new, I\\'m sure you\\'ll find it here.',\n",
       " ' I have to say that I am quite disappointed with this film. It\\'s a terrible film and I would never recommend it to anyone. The dialogue is so bad and it\\'s a slow motion movie that\\'s not as funny as it should be. I was so sad to find that my friend had to watch the film. He did love the film.\\n6. The whole thing is just so bad! I loved the way the story is told and the way the characters acted. A lot of the dialogue is just so bad. It\\'s so long and so repetitive!\\n7. I am not a huge fan of the movie and I do not think it\\'s a great movie. The way the characters are portrayed is just so stupid and pathetic. I found myself listening to a music video and not seeing the film. The characters are so over the top and the way the dialogue is presented is just so terrible. The only way to think that\\'s a good movie is to listen to this.\\n8. I don\\'t want to spoil anything. I was so excited to get this movie and it\\'s so funny. I hope you enjoy it.\\n1. Meryl Streep is very good in her nuanced and stoic performance as the infamous Lindy Chamberlain who was accused and tried for allegedly killing her own baby Azaria Chamberlain and using her alibi of ravenous dingoes as her defense. Based on the book \"Evil Angels\" and titled so in its Australian release, A CRY IN THE DARK is an ugly film to watch. It presents a scenario that\\'s all too real for us in America: the witch-hunt against a person deemed an easy target.2. *some spoilers*<br /><br />I was pleasantly surprised to find the harsh criticisms (acting, dated dialogue, unclear storyline) unfounded. Belafonte is great as a Brandoesque, menacing, swearing spirit who must earn his wings but is realistically ill-equipped from his past life to do',\n",
       " ' The only thing that stands out when you see this movie is its lack of gore. It\\'s a bit of a shame that we don\\'t see more of it.\\n6. There is a certain amount of \"wickedness\" in this movie, but I don\\'t think it is as much of a problem as it seems.\\n7. The only real \"good\" horror film is the \"Dirty Harry\" (a.k.a. \"The Dark Knight Returns\") which is a movie that has a lot of people talking about it. The only person who can truly say \"We don\\'t love this movie\" is that the director.\\n8. I can\\'t imagine how much more \"great\" that movie would have been if it were made by a serious horror film, and there are plenty of people who would not care about that. It\\'s not like this movie had to be a remake of the 1984 horror film \"The Dark Knight Returns\", which was a great horror film, but I can\\'t imagine how much of a difference it made.\\n9. The only movies that I really like about the film are \"The Exorcist\", \"The Conjuring\", and \"The Conjuring II\". The only movie that I really need to see is \"The Exorcist II\", and I love it. If there is one thing that I really do like about it, it is the story. This is a movie that is as much about the characters as it is about the plot.\\n10. The only difference between \"The Exorcist\" and \"The Exorcist II\" is that the character (the one who is the most powerful) is the one who is the most evil, and the movie is about him.\\n11. The only thing that I really like about this movie is the way the characters are treated. The way they are treated is in a way that is not very \"realistic\". I like the way they are treated',\n",
       " \" A classic for the time. The first movie was the first of many that were made in the '80s and '90s. It was a good one.\\n6. The first movie is not as good as the first one. The second one was good. But I think we're all going to agree on this: the second movie is a masterpiece.\\n7. The first movie is the best. The second one is a terrible one. But I think we're all going to agree on this: we're all going to agree on this: The first movie was a masterpiece.\\n8. The second movie is the worst. The third one is a great one. But I don't know what to say about the third one, but that's just me.\\n9. The first movie is great. The second one is terrible. But I think we're all going to agree on this: we're all going to agree on this: The first movie was a great one.\\n10. The second movie is awful. The third one is a terrible one. But I think we're all going to agree on this: we're all going to agree on this: The first movie was a great one.\\n11. The second movie is terrible. The third one is a terrible one. But I think we're all going to agree on this: we're all going to agree on this: The first movie was a great one.\\n12. The second movie is terrible. The third one is a terrible one. But I think we're all going to agree on this: we're all going to agree on this: The first movie was a great one.\\n13. The second movie is terrible. The third one is a terrible one. But I think we're all going to agree on this: we're all going to agree on this: The first movie was a great one.\\n14. The second movie is terrible. The third one is a terrible one\",\n",
       " ' I just finished watching The Killing of a Sacred Deer. I love this movie, but I don\\'t think it is a good movie. I think it is a bad one. The title (as opposed to the title of this review) was a bit of a misnomer, as it was just a title for a film that was essentially a glorified, uninteresting, and underused horror movie. I can\\'t help but wonder if the movie was meant to be a sequel to the first one. The second one was a bit better, but I don\\'t think so. It is just not a good movie.\\n6. The title was kind of a misspelling of \"fringe\". I have been using the word \"fringe\" a few times when talking about this movie and it is a misnomer. The term \"fringe\" is just a way to describe a subset of movies, a subset of movies that feature the same characters or plot twists, but are a bit different from each other. The term \"fringe\" is often used as a way to describe something that is not considered to be a \"fringe\" movie. (A fringe movie is a movie that features a lot of characters that do not fit neatly into a few categories. Some fringe movies are extremely complex, and some fringe movies are so elaborate that they are a little too complex for their own good.) The term \"fringe\" is also a misnomer, as it is used in a way that doesn\\'t really make sense to me and I would like to know why.\\n7. I like this movie. I am not an expert on horror movies, and I am not a fan of the movies that are based on them. I think this movie was a good idea and a good movie. I think it should be re-released. I think it should be re-released. I think it should be re-released. I think it should be re-',\n",
       " ' The only thing I can say is, this is a great movie. I will be giving it a 5/5.\\n\\n6. The story is a bit out of date, but the performances are outstanding. A lot of the action is so well done that we understand why they were cast. It\\'s a great movie, and is the perfect antidote to the constant barrage of \"bad movies\" that have been released. I wish the movie would have been remade and recast, but the only difference is that it is much better.\\n\\n7. The story is well done, and I will be giving it a 5/5.\\n\\n8. The soundtrack is phenomenal. It\\'s all there in the music, and it is absolutely gorgeous. The music is fantastic and I love the way it plays. It is a really good performance.\\n\\n9. The ending is really nice and it\\'s all in the ending. The ending is really good. The ending is really good.\\n\\n10. The ending is very good. The ending is very good.\\n\\n11. The ending is really good. The ending is really good.\\n\\n12. The ending is really good. The ending is really good.\\n\\n13. The ending is really good. The ending is really good.\\n\\n14. The ending is really good. The ending is really good.\\n\\n15. The ending is really good. The ending is really good.\\n\\n16. It\\'s not as bad as some of the other movies, and it\\'s not as bad as some of the others. It\\'s just a great movie.\\n\\n17. The ending is great. The ending is great.\\n\\n18. The ending is amazing. The ending is amazing.\\n\\n19. The ending is awesome. The ending is amazing.\\n\\n20. The ending is amazing. The ending is amazing.\\n\\n21. The ending is amazing. The ending is',\n",
       " ' The \"brave young woman\" thing was a bit of a stretch. I like this film because it\\'s more than a little bit of a gothic \"torture\" and it\\'s a bit of a cliche in that it\\'s so well done, but it\\'s also a bit of a \"fuck it, what happened to you?\" kind of movie.\\n6. Horror movies are better when they don\\'t feel like they\\'re set in a black-and-white world. I mean, they\\'re not, but you can\\'t really tell if they\\'re good or bad. The film is not terribly scary, but it\\'s not bad either. The film, like most of the other films I\\'ve seen, is a bit of a dorky, low-budget, low-budget, low-budget, low-budget, low-budget, low-budget, low-budget, low-budget, low-budget, low-budget, and it\\'s also not particularly good, but it\\'s still a good movie.\\n7. The soundtrack is great, and it\\'s pretty good too.\\n8. The film is pretty good too, and it\\'s probably the best horror movie I\\'ve ever seen.\\n9. There\\'s also a lot of good stuff in this movie, but it\\'s not as good as the other films.\\n10. I love this movie. I really do.\\nAll of the reviews.\\nThis is not a bad movie, it\\'s not as bad as the other films I\\'ve seen, and it\\'s not as bad as the other gothic horror films. I mean, it\\'s not the worst movie in the bunch, it\\'s not as bad as the other gothic horror films, but it\\'s not as bad as the other gothic horror films. I mean, it\\'s not as bad as the other gothic horror films, but it\\'s not as bad as the other goth']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# positive_prompt = subjective_prompt\n",
    "# negative_prompt = objetive_prompt\n",
    "positive_prompt_size = len(positive_prompt)\n",
    "negative_prompt_size = len(negative_prompt)\n",
    "# prompt_size = len(prompt)\n",
    "prompts = [positive_prompt, negative_prompt] * (batch_size // 2)\n",
    "# prompts = [prompt] * batch_size\n",
    "encoded_input = gpt_tokenizer(prompts, return_tensors='pt', padding=True)\n",
    "encoded_input.to(device)\n",
    "\n",
    "def generate_fake() -> list[str]:\n",
    "    output = generator.generate(**encoded_input, temperature=0.6, do_sample=True, max_new_tokens=400)\n",
    "    texts = gpt_tokenizer.batch_decode(output, skip_special_tokens=True)\n",
    "    samples =[]\n",
    "    # for i in range(0, len(texts)):\n",
    "    #     samples.append(texts[i][prompt_size:])\n",
    "    for i in range(0, len(texts), 2):\n",
    "        samples.append(texts[i][positive_prompt_size:])\n",
    "        samples.append(texts[i+1][negative_prompt_size:])\n",
    "    return samples\n",
    "\n",
    "generate_fake()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_dataloader: DataLoader, epoch_i: int, avg_train_loss_g: float, avg_train_loss_d: float, training_time: int,\n",
    "         training_stats: List[Dict]):\n",
    "    \"\"\"Perform test step at the end of one epoch\"\"\"\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Test...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    discriminator.eval()\n",
    "\n",
    "    # Tracking variables\n",
    "    total_test_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels_ids = []\n",
    "\n",
    "    # loss\n",
    "    nll_loss = torch.nn.CrossEntropyLoss(ignore_index=-1)\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for text, input_mask, label, label_mask in test_dataloader:\n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():\n",
    "            _, logits, probs = discriminator(text, input_mask)\n",
    "            filtered_logits = logits[:, 0:-1]\n",
    "            total_test_loss += nll_loss(filtered_logits, label)\n",
    "\n",
    "        # Accumulate the predictions and the input labels\n",
    "        _, preds = torch.max(filtered_logits, 1)\n",
    "        all_preds += preds.detach().cpu()\n",
    "        all_labels_ids += label.detach().cpu()\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    all_preds = torch.stack(all_preds).numpy()\n",
    "    all_labels_ids = torch.stack(all_labels_ids).numpy()\n",
    "    test_accuracy = np.sum(all_preds == all_labels_ids) / len(all_preds)\n",
    "    print(\"  Accuracy: {0:.3f}\".format(test_accuracy))\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_test_loss = total_test_loss / len(test_dataloader)\n",
    "    avg_test_loss = avg_test_loss.item()\n",
    "\n",
    "    # Measure how long the validation run took.\n",
    "    test_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"  Test Loss: {0:.3f}\".format(avg_test_loss))\n",
    "    print(\"  Test took: {:}\".format(test_time))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append({\n",
    "        'epoch': epoch_i + 1,\n",
    "        'Training Loss generator': avg_train_loss_g,\n",
    "        'Training Loss discriminator': avg_train_loss_d,\n",
    "        'Valid. Loss': avg_test_loss,\n",
    "        'Valid. Accur.': test_accuracy,\n",
    "        # 'Valid. F1': f1_score(all_labels_ids, all_preds),\n",
    "        # 'Valid. Recall': recall_score(all_labels_ids, all_preds),\n",
    "        # 'Valid. Precision': precision_score(all_labels_ids, all_preds),\n",
    "        'Training Time': training_time,\n",
    "        'Test Time': test_time\n",
    "    })\n",
    "    return test_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 50 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss generetor: 0.530\n",
      "  Average training loss discriminator: 1.948\n",
      "  Training epoch took: 0:12:34\n",
      "  Fakes correct discriminared: 164\n",
      "Saving the models...............................\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.500\n",
      "  Test Loss: 0.696\n",
      "  Test took: 0:02:30\n",
      "Initial score set at 0.500040\n",
      "\n",
      "======== Epoch 2 / 50 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss generetor: 0.620\n",
      "  Average training loss discriminator: 1.652\n",
      "  Training epoch took: 0:11:59\n",
      "  Fakes correct discriminared: 231\n",
      "Saving the models...............................\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.500\n",
      "  Test Loss: 0.694\n",
      "  Test took: 0:02:28\n",
      "\n",
      "======== Epoch 3 / 50 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss generetor: 0.644\n",
      "  Average training loss discriminator: 1.592\n",
      "  Training epoch took: 0:11:41\n",
      "  Fakes correct discriminared: 235\n",
      "Saving the models...............................\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.503\n",
      "  Test Loss: 0.695\n",
      "  Test took: 0:02:24\n",
      "Improvement found: 0.503080 (previous best: 0.500040)\n",
      "\n",
      "======== Epoch 4 / 50 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss generetor: 0.672\n",
      "  Average training loss discriminator: 1.475\n",
      "  Training epoch took: 0:11:21\n",
      "  Fakes correct discriminared: 242\n",
      "Saving the models...............................\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.497\n",
      "  Test Loss: 0.698\n",
      "  Test took: 0:02:25\n",
      "\n",
      "======== Epoch 5 / 50 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss generetor: 0.605\n",
      "  Average training loss discriminator: 1.648\n",
      "  Training epoch took: 0:11:20\n",
      "  Fakes correct discriminared: 236\n",
      "Saving the models...............................\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.641\n",
      "  Test Loss: 0.664\n",
      "  Test took: 0:02:24\n",
      "Improvement found: 0.641120 (previous best: 0.503080)\n",
      "\n",
      "======== Epoch 6 / 50 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss generetor: 0.673\n",
      "  Average training loss discriminator: 1.400\n",
      "  Training epoch took: 0:11:18\n",
      "  Fakes correct discriminared: 243\n",
      "Saving the models...............................\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.545\n",
      "  Test Loss: 0.706\n",
      "  Test took: 0:02:25\n",
      "\n",
      "======== Epoch 7 / 50 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss generetor: 0.676\n",
      "  Average training loss discriminator: 1.291\n",
      "  Training epoch took: 0:11:19\n",
      "  Fakes correct discriminared: 243\n",
      "Saving the models...............................\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.534\n",
      "  Test Loss: 0.760\n",
      "  Test took: 0:02:24\n",
      "\n",
      "======== Epoch 8 / 50 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss generetor: 0.670\n",
      "  Average training loss discriminator: 1.216\n",
      "  Training epoch took: 0:11:14\n",
      "  Fakes correct discriminared: 242\n",
      "Saving the models...............................\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.636\n",
      "  Test Loss: 0.713\n",
      "  Test took: 0:02:24\n",
      "\n",
      "======== Epoch 9 / 50 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss generetor: 0.653\n",
      "  Average training loss discriminator: 1.099\n",
      "  Training epoch took: 0:11:17\n",
      "  Fakes correct discriminared: 235\n",
      "Saving the models...............................\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.619\n",
      "  Test Loss: 0.997\n",
      "  Test took: 0:02:24\n",
      "\n",
      "======== Epoch 10 / 50 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss generetor: 0.691\n",
      "  Average training loss discriminator: 1.208\n",
      "  Training epoch took: 0:11:14\n",
      "  Fakes correct discriminared: 247\n",
      "Saving the models...............................\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.644\n",
      "  Test Loss: 0.728\n",
      "  Test took: 0:02:24\n",
      "Improvement found: 0.644040 (previous best: 0.641120)\n",
      "\n",
      "======== Epoch 11 / 50 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss generetor: 0.683\n",
      "  Average training loss discriminator: 0.887\n",
      "  Training epoch took: 0:11:14\n",
      "  Fakes correct discriminared: 244\n",
      "Saving the models...............................\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.656\n",
      "  Test Loss: 0.980\n",
      "  Test took: 0:02:24\n",
      "Improvement found: 0.655960 (previous best: 0.644040)\n",
      "\n",
      "======== Epoch 12 / 50 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss generetor: 0.688\n",
      "  Average training loss discriminator: 0.815\n",
      "  Training epoch took: 0:11:14\n",
      "  Fakes correct discriminared: 246\n",
      "Saving the models...............................\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.596\n",
      "  Test Loss: 1.351\n",
      "  Test took: 0:02:24\n",
      "\n",
      "======== Epoch 13 / 50 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss generetor: 0.674\n",
      "  Average training loss discriminator: 0.822\n",
      "  Training epoch took: 0:11:14\n",
      "  Fakes correct discriminared: 245\n",
      "Saving the models...............................\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.669\n",
      "  Test Loss: 1.196\n",
      "  Test took: 0:02:24\n",
      "Improvement found: 0.668920 (previous best: 0.655960)\n",
      "\n",
      "======== Epoch 14 / 50 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss generetor: 0.678\n",
      "  Average training loss discriminator: 0.823\n",
      "  Training epoch took: 0:11:18\n",
      "  Fakes correct discriminared: 245\n",
      "Saving the models...............................\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.662\n",
      "  Test Loss: 1.298\n",
      "  Test took: 0:02:24\n",
      "\n",
      "======== Epoch 15 / 50 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss generetor: 0.647\n",
      "  Average training loss discriminator: 1.072\n",
      "  Training epoch took: 0:11:16\n",
      "  Fakes correct discriminared: 233\n",
      "Saving the models...............................\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.558\n",
      "  Test Loss: 0.905\n",
      "  Test took: 0:02:24\n",
      "\n",
      "======== Epoch 16 / 50 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss generetor: 0.639\n",
      "  Average training loss discriminator: 0.984\n",
      "  Training epoch took: 0:11:16\n",
      "  Fakes correct discriminared: 202\n",
      "Saving the models...............................\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.574\n",
      "  Test Loss: 1.388\n",
      "  Test took: 0:02:24\n",
      "\n",
      "======== Epoch 17 / 50 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss generetor: 0.681\n",
      "  Average training loss discriminator: 0.847\n",
      "  Training epoch took: 0:11:15\n",
      "  Fakes correct discriminared: 209\n",
      "Saving the models...............................\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.657\n",
      "  Test Loss: 1.396\n",
      "  Test took: 0:02:25\n",
      "\n",
      "======== Epoch 18 / 50 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss generetor: 0.686\n",
      "  Average training loss discriminator: 0.745\n",
      "  Training epoch took: 0:11:16\n",
      "  Fakes correct discriminared: 246\n",
      "Saving the models...............................\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.659\n",
      "  Test Loss: 1.634\n",
      "  Test took: 0:02:24\n",
      "Early stopping triggered after 5 epochs with no improvement.\n",
      "early stopping. Training Stopped\n"
     ]
    }
   ],
   "source": [
    "for epoch_i in range(0, num_train_epochs):\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, num_train_epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    tr_g_loss = 0\n",
    "    tr_d_loss = 0\n",
    "    true_fakes = 0\n",
    "\n",
    "    # Put the model into training mode.\n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "\n",
    "    for step, (text, input_mask, label, label_mask) in enumerate(train_dataloader):\n",
    "        # Progress update every print_each_n_step batches.\n",
    "        if step % print_each_n_step == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "\n",
    "        gen_samples = generate_fake()\n",
    "        encode_result = tokenizer.batch_encode_plus(gen_samples, add_special_tokens=True, max_length=seq_size, padding=\"max_length\", truncation=True, return_tensors='pt')\n",
    "        gen_rep = encode_result['input_ids'].to(device)\n",
    "        gen_att_mask = encode_result['attention_mask'].to(device)\n",
    "\n",
    "        \n",
    "        # Generate the output of the Discriminator for real and fake data.\n",
    "        # First, we put together the output of the tranformer and the generator\n",
    "        disciminator_input = torch.cat([text, gen_rep], dim=0)\n",
    "        # Also, join with the fake sentences mask\n",
    "\n",
    "        input_mask = torch.cat([input_mask, gen_att_mask], dim=0)\n",
    "        # Then, we select the output of the disciminator\n",
    "        features, logits, probs = discriminator(disciminator_input, input_mask)\n",
    "\n",
    "        # Finally, we separate the discriminator's output for the real and fake\n",
    "        # data\n",
    "        split_size = batch_size\n",
    "        features_list = torch.split(features, split_size)\n",
    "        # Splits the tensor into chunks. Each chunk is a view of the original tensor\n",
    "        D_real_features = features_list[0]\n",
    "        D_fake_features = features_list[1]\n",
    "\n",
    "        logits_list = torch.split(logits, split_size)\n",
    "        D_real_logits = logits_list[0]\n",
    "\n",
    "        probs_list = torch.split(probs, split_size)\n",
    "        D_real_probs = probs_list[0]\n",
    "        D_fake_probs = probs_list[1]\n",
    "\n",
    "        # Fake labels counting\n",
    "        true_fakes_batch = (torch.argmax(D_fake_probs, dim=1) == len(labels)).sum().item()\n",
    "        true_fakes += true_fakes_batch\n",
    "\n",
    "        # ---------------------------------\n",
    "        #  LOSS evaluation\n",
    "        # ---------------------------------\n",
    "        # Generator's LOSS estimation\n",
    "        g_loss_d = -1 * torch.mean(torch.log(1 - D_fake_probs[:, -1] + epsilon))\n",
    "        g_feat_reg = 0 * torch.mean(\n",
    "            torch.pow(torch.mean(D_real_features, dim=0) - torch.mean(D_fake_features, dim=0), 2)\n",
    "            )\n",
    "        g_loss = g_loss_d + g_feat_reg\n",
    "        # print(g_loss_d, g_feat_reg)\n",
    "\n",
    "        # Disciminator's LOSS estimation\n",
    "        logits = D_real_logits[:, 0:-1]\n",
    "        log_probs = F.log_softmax(logits, dim=-1)\n",
    "\n",
    "        # The discriminator provides an output for labeled and unlabeled real data\n",
    "        # so the loss evaluated for unlabeled data is ignored (masked)\n",
    "        label2one_hot = torch.nn.functional.one_hot(label, len(labels))\n",
    "        per_example_loss = -torch.sum(label2one_hot * log_probs, dim=-1)\n",
    "        per_example_loss = torch.masked_select(per_example_loss, label_mask)\n",
    "        labeled_example_count = per_example_loss.type(torch.float32).numel()\n",
    "\n",
    "        # It may be the case that a batch does not contain labeled examples,\n",
    "        # so the \"supervised loss\" in this case is not evaluated\n",
    "        if labeled_example_count == 0:\n",
    "            D_L_Supervised = 0\n",
    "        else:\n",
    "            D_L_Supervised = torch.div(torch.sum(per_example_loss.to(device)), labeled_example_count)\n",
    "\n",
    "        D_L_unsupervised1U = -1 * torch.mean(torch.log(1 - D_real_probs[:, -1] + epsilon))\n",
    "        D_L_unsupervised2U = -1 * torch.mean(torch.log(D_fake_probs[:, -1] + epsilon))\n",
    "        d_loss = D_L_Supervised + D_L_unsupervised1U + D_L_unsupervised2U\n",
    "        # print(D_L_Supervised, D_L_unsupervised1U, D_L_unsupervised2U)\n",
    "\n",
    "        # ---------------------------------\n",
    "        #  OPTIMIZATION\n",
    "        # ---------------------------------\n",
    "        # Avoid gradient accumulation\n",
    "        gen_optimizer.zero_grad()\n",
    "        dis_optimizer.zero_grad()\n",
    "\n",
    "        # Calculate weigth updates\n",
    "        # retain_graph=True is required since the underlying graph will be deleted after backward\n",
    "        g_loss.backward(retain_graph=True)\n",
    "        d_loss.backward(retain_graph=True)\n",
    "\n",
    "        # Apply modifications\n",
    "        gen_optimizer.step()\n",
    "        dis_optimizer.step()\n",
    "\n",
    "        # Save the losses to print them later\n",
    "        tr_g_loss += g_loss.item()\n",
    "        tr_d_loss += d_loss.item()\n",
    "\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss_g = tr_g_loss / len(train_dataloader)\n",
    "    avg_train_loss_d = tr_d_loss / len(train_dataloader)\n",
    "\n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss generetor: {0:.3f}\".format(avg_train_loss_g))\n",
    "    print(\"  Average training loss discriminator: {0:.3f}\".format(avg_train_loss_d))\n",
    "    print(\"  Training epoch took: {:}\".format(training_time))\n",
    "    print(\"  Fakes correct discriminared: {}\".format(true_fakes))\n",
    "\n",
    "    print(\"Saving the models...............................\")\n",
    "    # Saving the model\n",
    "    torch.save(generator, '../models/generator')\n",
    "    torch.save(discriminator, '../models/discriminator')\n",
    "\n",
    "    test_accuracy = test(\n",
    "        test_dataloader, epoch_i,\n",
    "        avg_train_loss_g, avg_train_loss_d, training_time, training_stats\n",
    "    )\n",
    "    training_stats[-1]['True fakes'] = true_fakes\n",
    "\n",
    "    # save_stats(training_stats, trial)\n",
    "\n",
    "    # check early stopping\n",
    "    early_stopping(test_accuracy)\n",
    "    if early_stopping.early_stop:\n",
    "        print('early stopping. Training Stopped')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mestrado",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
