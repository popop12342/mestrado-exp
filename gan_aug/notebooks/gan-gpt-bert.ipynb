{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../core')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/mestrado/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2Model, AutoModelForCausalLM\n",
    "\n",
    "import time\n",
    "from typing import Dict, List\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import numpy as np\n",
    "import optuna\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from data_utils import format_time, save_stats\n",
    "from dataloader import create_bert_dataloaders\n",
    "from dataset_loader import dataset_loader\n",
    "from optuna.trial import Trial\n",
    "from torch.utils.data import DataLoader\n",
    "from models.bert_discriminator import BERTDiscriminator, model_name\n",
    "from models.generator import Generator\n",
    "from transformers import AutoTokenizer\n",
    "from util.early_stopping import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences, train_labels, _, _ = dataset_loader.load_dataset('aclImdb_001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '0', '0', '0', '0', '0', '0', '0', '0', '0']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What was Steven Seagal thinking? I mean firstly I love Seagal. I love all his movies up to the mid 2000s. His early stuff is some of the best in the genre. This however does not live up to its excellent name. Attack Force (with protagonist Marshall Lawson {Seagal}) would be expected to be a mindless action movie with Seagal in typical one-liner ass kicking form. However, what we get is a crime mystery, bordering on a political thriller with little or no action. Seagal is always in shadows because of his weight. I could not follow this story. There\\'s people who mutate to superhumans when they take a drug. What happened in this movie. The dubbing of Seagal is a disgrace, a shambles and a shame. Why dub the man? The story is terrible. This got a 2/10 from me because of the scene where Seagal asks for backup despite having an army with him, and an hilarious fight scene where seagal swings his hands like a girl facing the camera! \"Revenge is a two way street\" seagal says in this movie...well forget revenge Steven, you need redemption!'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences[-8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "gpt_tokenizer = GPT2Tokenizer.from_pretrained('gpt2', padding_side='left')\n",
    "generator = AutoModelForCausalLM.from_pretrained('gpt2')\n",
    "gpt_tokenizer.pad_token = gpt_tokenizer.eos_token\n",
    "positive_prompt = \"Here are 3 positive movie review from IMDB website written in a user post:\\n 1. For a movie that gets no respect there sure are a lot of memorable quotes listed for this gem. Imagine a movie where Joe Piscopo is actually funny! Maureen Stapleton is a scene stealer. The Moroni character is an absolute scream. Watch for Alan \\\"The Skipper\\\" Hale jr. as a police Sgt\\n 2. A solid, if unremarkable film. Matthau, as Einstein, was wonderful. My favorite part, and the only thing that would make me go out of my way to see this again, was the wonderful scene with the physicists playing badmitton, I loved the sweaters and the conversation while they waited for Robbins to retrieve the birdie.\\n 3. \"\n",
    "# positive_prompt = \"İşte Türkçe olumlu bir ürün yorumu:\\n\\n\"\n",
    "negative_prompt = \"Here are 3 negative movie review from IMDB website written in a user post:\\n 1. Wow! I remember so many awful films that loosely revolved around high school from the early 1980s. They usually had someincredibly strained plot and lots of 27 year old actors pretending to be students. As I watched this film I felt a little of the nostalgia of growing up in the 1980s. However, then I find out that this film was made in 1989? Say what! Well, the nostalgia factor ends right there, this is just bad. The plot has the city preparing to close a high school and threatening to bus all of the students to inner city high schools. Which is odd, in that the students at this school are both wealthy and abundant. In fact, the main character lives in a mansion. Makes you wonder how they cannot find money to keep this school alive, have they never heard of property taxes. Oh, but here is the kicker. The school board says that they will keep the school alive, if the students can raise $200,000. So the seniors go about doing this. Hmmm, you raise $200,000 but instead of saving that for college, you put it towards saving the high school that you are a Senior in? And why exactly would they close an overpopulated school before the year is out? And...ahh forget it, this film was stupid and made in 1989!?\\n 2. What was Steven Seagal thinking? I mean firstly I love Seagal. I love all his movies up to the mid 2000s. His early stuff is some of the best in the genre. This however does not live up to its excellent name. Attack Force (with protagonist Marshall Lawson {Seagal}) would be expected to be a mindless action movie with Seagal in typical one-liner ass kicking form. However, what we get is a crime mystery, bordering on a political thriller with little or no action. Seagal is always in shadows because of his weight. I could not follow this story. There\\'s people who mutate to superhumans when they take a drug. What happened in this movie. The dubbing of Seagal is a disgrace, a shambles and a shame. Why dub the man? The story is terrible. This got a 2/10 from me because of the scene where Seagal asks for backup despite having an army with him, and an hilarious fight scene where seagal swings his hands like a girl facing the camera! \\\"Revenge is a two way street\\\" seagal says in this movie...well forget revenge Steven, you need redemption!\\n 3. \"\n",
    "# negative_prompt = \"İşte Türkçe olumsuz bir ürün yorumu:\\n\\n\"\n",
    "# prompt = \"Here is an example of helpdesk emails texts about one of the topics General Inquiry, Human Resources, Billing and Payments, Sales and Pre-Sales, IT Support, Customer Service, Product Support, Returns and Exchanges, Service Outages and Maintenance or Technical Support: \\n\\n\"\n",
    "# prompt = 'ประโยคภาษาไทยต่อไปนี้มีเนื้อหาเชิงบวก เชิงลบ หรือเป็นกลาง:\\n\\n'\n",
    "encoded_input = gpt_tokenizer([positive_prompt, negative_prompt], return_tensors='pt', padding=True)\n",
    "output = generator.generate(**encoded_input, temperature=0.9, do_sample=True, max_length=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>Here are 3 positive movie review from IMDB website written in a user post:\\n 1. For a movie that gets no respect there sure are a lot of memorable quotes listed for this gem. Imagine a movie where Joe Piscopo is actually funny! Maureen Stapleton is a scene stealer. The Moroni character is an absolute scream. Watch for Alan \"The Skipper\" Hale jr. as a police Sgt\\n 2. A solid, if unremarkable film. Matthau, as Einstein, was wonderful. My favorite part, and the only thing that would make me go out of my way to see this again, was the wonderful scene with the physicists playing badmitton, I loved the sweaters and the conversation while they waited for Robbins to retrieve the birdie.\\n 3. \\xa0There\\'s something about \"Nights at the Zoo\" that I really enjoyed. It made me really glad that the movie gave away a little bit about the zoo. The movie opened right off the bat with this one. The opening of this film gives a lot of background to the movie, from the start to when the audience is in danger of being attacked, the time period before the shots start and the time of the escape (which is an option if the movie is released in theaters). The movie is more of a prologue of the series, so it could also have some of that theme, and be a nice little introduction to the character of Einstein (as seen in the scene where we watch the story unfold).\\n4. \\xa0What a great movie to be a part of with the movie being so good that it almost never gets rewatched. It had a good chance to do a very nice movie in the early part of the series and still get rewatched. I thought a lot about looking at this movie through the eyes of a kid I know. The movie is great, and I think a lot of people should really watch it, there are a lot of nice moments in this film.\\nThe Best Movies in the Series.<|endoftext|><|endoftext|><|endoftext|>',\n",
       " 'Here are 3 negative movie review from IMDB website written in a user post:\\n 1. Wow! I remember so many awful films that loosely revolved around high school from the early 1980s. They usually had someincredibly strained plot and lots of 27 year old actors pretending to be students. As I watched this film I felt a little of the nostalgia of growing up in the 1980s. However, then I find out that this film was made in 1989? Say what! Well, the nostalgia factor ends right there, this is just bad. The plot has the city preparing to close a high school and threatening to bus all of the students to inner city high schools. Which is odd, in that the students at this school are both wealthy and abundant. In fact, the main character lives in a mansion. Makes you wonder how they cannot find money to keep this school alive, have they never heard of property taxes. Oh, but here is the kicker. The school board says that they will keep the school alive, if the students can raise $200,000. So the seniors go about doing this. Hmmm, you raise $200,000 but instead of saving that for college, you put it towards saving the high school that you are a Senior in? And why exactly would they close an overpopulated school before the year is out? And...ahh forget it, this film was stupid and made in 1989!?\\n 2. What was Steven Seagal thinking? I mean firstly I love Seagal. I love all his movies up to the mid 2000s. His early stuff is some of the best in the genre. This however does not live up to its excellent name. Attack Force (with protagonist Marshall Lawson {Seagal}) would be expected to be a mindless action movie with Seagal in typical one-liner ass kicking form. However, what we get is a crime mystery, bordering on a political thriller with little or no action. Seagal is always in shadows because of his weight. I could not follow this story. There\\'s people who mutate to superhumans when they take a drug. What happened in this movie. The dubbing of Seagal is a disgrace, a shambles and a shame. Why dub the man? The story is terrible. This got a 2/10 from me because of the scene where Seagal asks for backup despite having an army with him, and an hilarious fight scene where seagal swings his hands like a girl facing the camera! \"Revenge is a two way street\" seagal says in this movie...well forget revenge Steven, you need redemption!\\n 3. ??????? Is there something wrong with this movie? Oh, well here is 3 good reasons why Seagal was not a good movie! 1. The title. He was not a good movie. 2. ??????? Was he a good movie as opposed to some of his other lesser productions and he has no redeeming effect? This is a great movie, so what is it? Seagal makes bad movies. But even with what he has. All of his films made. There are no weak references in his other movies. He has so many terrible ideas. He doesn\\'t have a bad concept, he does not have the art, and he has no great characters. This is a good movie, and Seagal is not a bad movie. It is the worst of all movie ever. Let the reviews speak for themselves!\\n-T.\\nPosted by Steven Seagal at 3:49 am\\nI\\'ve taken some time out of my life to read this review. I was really looking forward to hearing about this film. I did not read any reviews of this movie. That being said, I\\'m very excited for some of the new movies from Steven Seagal, because I have been waiting for something new to come this fall, but I']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_tokenizer.batch_decode(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_each_n_step = 50\n",
    "num_train_epochs = 50\n",
    "noise_size = 1\n",
    "batch_size = 8\n",
    "epsilon = 1e-8\n",
    "initial_temp = 1.0\n",
    "anneal_rate = 0.95\n",
    "min_temp = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS backend\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.backends.mps.is_available():\n",
    "    print('Using MPS backend')\n",
    "    device = torch.device('mps')\n",
    "elif torch.cuda.is_available():\n",
    "    # Tell PyTorch to use the GPU.\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using dataset task-oriented-dialog_th_001\n"
     ]
    }
   ],
   "source": [
    "labels = dataset_loader.get_labels('task-oriented-dialog_th_001')\n",
    "\n",
    "train_dataloader, test_dataloader, seq_size = create_bert_dataloaders(\n",
    "    'task-oriented-dialog_th_001', batch_size=batch_size, device=device,\n",
    "    tokenizer=tokenizer)\n",
    "\n",
    "# Models\n",
    "discriminator = BERTDiscriminator(1, seq_size, device, num_labels=len(labels))\n",
    "\n",
    "# print(generator)\n",
    "# print('generator parameters: ' + str(sum(p.numel() for p in generator.parameters() if p.requires_grad)))\n",
    "# print(discriminator)\n",
    "# print('discriminator parameters: ' + str(sum(p.numel() for p in discriminator.parameters() if p.requires_grad)))\n",
    "\n",
    "generator.to(device)\n",
    "discriminator.to(device)\n",
    "if torch.cuda.is_available():\n",
    "    generator.cuda()\n",
    "    discriminator.cuda()\n",
    "\n",
    "# Training\n",
    "training_stats = []\n",
    "\n",
    "g_vars = [v for v in generator.parameters()]\n",
    "d_vars = [v for v in discriminator.parameters()]\n",
    "\n",
    "gen_optimizer = torch.optim.AdamW(g_vars, lr=5e-5)\n",
    "dis_optimizer = torch.optim.AdamW(d_vars, lr=5e-5)\n",
    "\n",
    "early_stopping = EarlyStopping(patience=5, min_delta=0.001, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/mestrado/lib/python3.11/site-packages/transformers/pytorch_utils.py:337: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"\\xa0This one was a must-watch for anyone who loves science fiction. It's a fantastic read.\\n4. \\xa0The movie has one of the best scenes of all time, which is how I found it. The ending is a beautiful one, but the movie is also a good film overall.\\n5. \\xa0This is one of my all time favorites.\\n6. \\xa0This is my favorite movie.\\n7. \\xa0This is my favorite movie, and I think it's the best movie of all time.\\n8. \\xa0This is by far the best movie ever made.\\n9. \\xa0This is by far the best movie ever made, and I think it's the best movie ever made.\\n10. \\xa0This is by far the best movie ever made.\\n11. \\xa0This is by far the best movie ever made.\\n12. \\xa0This is by far the best movie ever made.\\n13. \\xa0This is by far the best movie ever made.\\n14. \\xa0This is by far the best movie ever made.\\n15. \\xa0This is by far the best movie ever made.\\n16. \\xa0This is by far the best movie ever made.\",\n",
       " '\\xa0Sebastian is my favorite character in this movie. He is a good actor. He gets to see the characters and is a good person. He is a good man. He has the right to be in this movie and to be a good man. He is not a bad guy, but he is a bad guy. He is a bad man. He is a bad man. He is a bad man. He is a bad man. He is a bad man. He is a bad man. He is a bad man. He is a bad man. He is a bad man. He is a bad man. He is a bad man. He is a bad man. He is a bad man. He is a bad man. He is a bad man. He is a bad man. He is a bad man. He is a bad man. He is a bad man. He is a bad man.\\n4. \\xa0The characters are really good. The characters are really good. The characters are really good. The characters are really good. The characters are really good. The characters are really good. The characters are really good. The characters are really good. The characters are really good. The characters are really good. The characters are really',\n",
       " '\\xa0This is my very favorite movie of the year. It is a terrific film that will make you cry.\\n4. \\xa0The film is not as good as it seems to be. There are a lot of great things about it that are not mentioned. I would say this is a movie that deserves a good review.\\n5. \\xa0The opening credits are pretty cool. The closing credits are not. I do not know if this was the best film of the year, but I am sure the best movie of the year was probably the best movie of the year.',\n",
       " '\\xa0What did you think of the movie? What did you think of the movie you liked and liked it?\\n4. \\xa0Do you think this movie is a good movie? Do you think this movie is a good movie for you?\\n5. \\xa0What do you think of the movie? \\xa0Would you like it to be a sequel?\\n6. \\xa0What is your response? \\xa0What is your opinion? Do you think this movie is a bad movie?\\n7. \\xa0What do you think of the movie? \\xa0Would you like it to be a sequel?\\n8. \\xa0What do you think of the movie? \\xa0Would you like it to be a sequel?\\n9. \\xa0What do you think of the movie? \\xa0Would you like it to be a sequel?\\n10. \\xa0What do you think of the movie? \\xa0Would you like it to be a sequel?\\n11. \\xa0What do you think of the movie? \\xa0Would you like it to be a sequel?\\n12. \\xa0What do you think of the movie? \\xa0Would you like it to be a sequel?\\n13. \\xa0What do you think of the movie',\n",
       " '\\xa0A great movie. I am so glad that IMDB was able to put it together, and I will definitely be seeing more of it.\\xa0 I highly recommend this movie to anyone looking for a funny, funny, funny and unique look at science, and especially a movie that is a great read.\\n2. For a movie that gets no respect there sure are a lot of memorable quotes listed for this gem. Imagine a movie where Joe Piscopo is actually funny! Maureen Stapleton is a scene stealer. The Moroni character is an absolute scream. Watch for Alan \"The Skipper\" Hale jr. as a police Sgt\\n1. For a movie that gets no respect there sure are a lot of memorable quotes listed for this gem. Imagine a movie where Joe Piscopo is actually funny! Maureen Stapleton is a scene stealer. The Moroni character is an absolute scream. Watch for Alan \"The Skipper\" Hale jr. as a police Sgt\\nI think this might be the best movie I ever watched. It is a great movie that will be missed by most.\\xa0 I am a big fan of science fiction and I am very happy to see a movie that was so well written and made.',\n",
       " \"\\xa0That's a pretty big list. I like it when I see bad movies. You don't like it when you're bad. I like when you like bad movies just because they're good. But I don't like bad movies because they're bad. I like bad movies because they're bad because they're bad. That's the part I really like. \\xa0I like bad movies because they're good because they're good, but I don't like bad movies because they're bad because they're bad. So if you watch a bad movie and you have a bad feeling, you are better off watching a good movie. I think that's what makes the movie so good. \\xa0I think that's what makes the movie so good.\\n4. \\xa0I'm not saying that this movie is bad. I'm saying that it is really good. It is. I think it is. It feels like a good movie. I think it is. It's a great movie. It's a great movie. I think it is. It's a great movie. I think it is.\\n5. \\xa0I think it is. I think it is.\\n6. \\xa0I see a lot of bad movies. I see a lot of\",\n",
       " \"\\xa0A great movie that gets a bad review. I'm not sure how much of a bad review it is. I found out about it on my own.\\n4. The movie is a lot of fun. It got a lot of attention because of the amount of people who played it. I was able to get a few people to watch it, but I didn't really see enough of it. The movie is a lot of fun. It got a lot of attention because of the amount of people who played it. I was able to get a few people to watch it, but I didn't really see enough of it.\\n5. The movie is fun to watch. It's a lot of fun that it's mostly a movie about a young man trying to get into the world of physics and engineering. I don't think I've ever seen it in a movie like this. You can't go wrong with a movie like this.\\n6. The movie is a lot of fun. It's a lot of fun that it's mostly a movie about a young man trying to get into the world of physics and engineering. I don't think I've ever seen it in a movie like this. You can't go wrong with a movie like this.\\n7\",\n",
       " \"\\xa0I really enjoyed this one. It had a great story and some great action. There's no shortage of bad movies in the genre, but I would say this one is the best I've seen here. I really like Seagal's work. I could not recommend this movie to anyone.\\n4. \\xa0Wow. This is an amazing movie. I really enjoyed this one. It had a great story and some great action. There's no shortage of bad movies in the genre, but I would say this one is the best I've seen here. I really like Seagal's work. I could not recommend this movie to anyone.\\n5. \\xa0I really liked this movie. It had a great story and some great action. There's no shortage of bad movies in the genre, but I would say this one is the best I've seen here. I really like Seagal's work. I could not recommend this movie to anyone.\\n6. \\xa0Wow. \\xa0This is a great movie. It had a great story and some great action. There's no shortage of bad movies in the genre, but I would say this one is the best I've seen here. I really like Seagal's work. I\"]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_prompt_size = len(positive_prompt)\n",
    "negative_prompt_size = len(negative_prompt)\n",
    "# prompt_size = len(prompt)\n",
    "prompts = [positive_prompt, negative_prompt] * (batch_size // 2)\n",
    "encoded_input = gpt_tokenizer(prompts, return_tensors='pt', padding=True)\n",
    "encoded_input.to(device)\n",
    "\n",
    "def generate_fake() -> list[str]:\n",
    "    output = generator.generate(**encoded_input, temperature=0.6, do_sample=True, max_length=800)\n",
    "    texts = gpt_tokenizer.batch_decode(output, skip_special_tokens=True)\n",
    "    samples =[]\n",
    "    # for i in range(0, len(texts)):\n",
    "    #     samples.append(texts[i][prompt_size:])\n",
    "    for i in range(0, len(texts), 2):\n",
    "        samples.append(texts[i][positive_prompt_size:])\n",
    "        samples.append(texts[i+1][negative_prompt_size:])\n",
    "    return samples\n",
    "\n",
    "generate_fake()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_dataloader: DataLoader, epoch_i: int, avg_train_loss_g: float, avg_train_loss_d: float, training_time: int,\n",
    "         training_stats: List[Dict]):\n",
    "    \"\"\"Perform test step at the end of one epoch\"\"\"\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Test...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    discriminator.eval()\n",
    "\n",
    "    # Tracking variables\n",
    "    total_test_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels_ids = []\n",
    "\n",
    "    # loss\n",
    "    nll_loss = torch.nn.CrossEntropyLoss(ignore_index=-1)\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for text, input_mask, label, label_mask in test_dataloader:\n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():\n",
    "            _, logits, probs = discriminator(text, input_mask)\n",
    "            filtered_logits = logits[:, 0:-1]\n",
    "            total_test_loss += nll_loss(filtered_logits, label)\n",
    "\n",
    "        # Accumulate the predictions and the input labels\n",
    "        _, preds = torch.max(filtered_logits, 1)\n",
    "        all_preds += preds.detach().cpu()\n",
    "        all_labels_ids += label.detach().cpu()\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    all_preds = torch.stack(all_preds).numpy()\n",
    "    all_labels_ids = torch.stack(all_labels_ids).numpy()\n",
    "    test_accuracy = np.sum(all_preds == all_labels_ids) / len(all_preds)\n",
    "    print(\"  Accuracy: {0:.3f}\".format(test_accuracy))\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_test_loss = total_test_loss / len(test_dataloader)\n",
    "    avg_test_loss = avg_test_loss.item()\n",
    "\n",
    "    # Measure how long the validation run took.\n",
    "    test_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"  Test Loss: {0:.3f}\".format(avg_test_loss))\n",
    "    print(\"  Test took: {:}\".format(test_time))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append({\n",
    "        'epoch': epoch_i + 1,\n",
    "        'Training Loss generator': avg_train_loss_g,\n",
    "        'Training Loss discriminator': avg_train_loss_d,\n",
    "        'Valid. Loss': avg_test_loss,\n",
    "        'Valid. Accur.': test_accuracy,\n",
    "        # 'Valid. F1': f1_score(all_labels_ids, all_preds),\n",
    "        # 'Valid. Recall': recall_score(all_labels_ids, all_preds),\n",
    "        # 'Valid. Precision': precision_score(all_labels_ids, all_preds),\n",
    "        'Training Time': training_time,\n",
    "        'Test Time': test_time\n",
    "    })\n",
    "    return test_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 50 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss generetor: 0.277\n",
      "  Average training loss discriminator: 2.795\n",
      "  Training epoch took: 0:00:46\n",
      "  Fakes correct discriminared: 0\n",
      "Saving the models...............................\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.385\n",
      "  Test Loss: 1.094\n",
      "  Test took: 0:00:10\n",
      "Initial score set at 0.385071\n",
      "\n",
      "======== Epoch 2 / 50 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss generetor: 0.298\n",
      "  Average training loss discriminator: 2.718\n",
      "  Training epoch took: 0:00:34\n",
      "  Fakes correct discriminared: 4\n",
      "Saving the models...............................\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.261\n",
      "  Test Loss: 1.105\n",
      "  Test took: 0:00:10\n",
      "\n",
      "======== Epoch 3 / 50 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss generetor: 0.348\n",
      "  Average training loss discriminator: 2.573\n",
      "  Training epoch took: 0:00:30\n",
      "  Fakes correct discriminared: 11\n",
      "Saving the models...............................\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.264\n",
      "  Test Loss: 1.097\n",
      "  Test took: 0:00:10\n",
      "\n",
      "======== Epoch 4 / 50 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss generetor: 0.456\n",
      "  Average training loss discriminator: 2.401\n",
      "  Training epoch took: 0:00:31\n",
      "  Fakes correct discriminared: 16\n",
      "Saving the models...............................\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.486\n",
      "  Test Loss: 1.008\n",
      "  Test took: 0:00:10\n",
      "Improvement found: 0.485782 (previous best: 0.385071)\n",
      "\n",
      "======== Epoch 5 / 50 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss generetor: 0.563\n",
      "  Average training loss discriminator: 2.069\n",
      "  Training epoch took: 0:00:31\n",
      "  Fakes correct discriminared: 16\n",
      "Saving the models...............................\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.628\n",
      "  Test Loss: 0.877\n",
      "  Test took: 0:00:10\n",
      "Improvement found: 0.627962 (previous best: 0.485782)\n",
      "\n",
      "======== Epoch 6 / 50 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss generetor: 0.654\n",
      "  Average training loss discriminator: 1.905\n",
      "  Training epoch took: 0:00:30\n",
      "  Fakes correct discriminared: 16\n",
      "Saving the models...............................\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.594\n",
      "  Test Loss: 0.843\n",
      "  Test took: 0:00:10\n",
      "\n",
      "======== Epoch 7 / 50 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss generetor: 0.717\n",
      "  Average training loss discriminator: 1.566\n",
      "  Training epoch took: 0:00:30\n",
      "  Fakes correct discriminared: 16\n",
      "Saving the models...............................\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.722\n",
      "  Test Loss: 0.815\n",
      "  Test took: 0:00:10\n",
      "Improvement found: 0.721564 (previous best: 0.627962)\n",
      "\n",
      "======== Epoch 8 / 50 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss generetor: 0.745\n",
      "  Average training loss discriminator: 1.530\n",
      "  Training epoch took: 0:00:31\n",
      "  Fakes correct discriminared: 16\n",
      "Saving the models...............................\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.656\n",
      "  Test Loss: 0.781\n",
      "  Test took: 0:00:10\n",
      "\n",
      "======== Epoch 9 / 50 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss generetor: 0.694\n",
      "  Average training loss discriminator: 1.463\n",
      "  Training epoch took: 0:00:31\n",
      "  Fakes correct discriminared: 16\n",
      "Saving the models...............................\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.710\n",
      "  Test Loss: 0.693\n",
      "  Test took: 0:00:10\n",
      "\n",
      "======== Epoch 10 / 50 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss generetor: 0.640\n",
      "  Average training loss discriminator: 1.366\n",
      "  Training epoch took: 0:00:30\n",
      "  Fakes correct discriminared: 16\n",
      "Saving the models...............................\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.757\n",
      "  Test Loss: 0.669\n",
      "  Test took: 0:00:10\n",
      "Improvement found: 0.756517 (previous best: 0.721564)\n",
      "\n",
      "======== Epoch 11 / 50 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss generetor: 0.681\n",
      "  Average training loss discriminator: 1.203\n",
      "  Training epoch took: 0:00:30\n",
      "  Fakes correct discriminared: 16\n",
      "Saving the models...............................\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.771\n",
      "  Test Loss: 0.731\n",
      "  Test took: 0:00:10\n",
      "Improvement found: 0.771327 (previous best: 0.756517)\n",
      "\n",
      "======== Epoch 12 / 50 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss generetor: 0.711\n",
      "  Average training loss discriminator: 1.071\n",
      "  Training epoch took: 0:00:30\n",
      "  Fakes correct discriminared: 16\n",
      "Saving the models...............................\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.751\n",
      "  Test Loss: 0.827\n",
      "  Test took: 0:00:10\n",
      "\n",
      "======== Epoch 13 / 50 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss generetor: 0.730\n",
      "  Average training loss discriminator: 0.989\n",
      "  Training epoch took: 0:00:30\n",
      "  Fakes correct discriminared: 16\n",
      "Saving the models...............................\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.742\n",
      "  Test Loss: 0.845\n",
      "  Test took: 0:00:10\n",
      "\n",
      "======== Epoch 14 / 50 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss generetor: 0.701\n",
      "  Average training loss discriminator: 0.929\n",
      "  Training epoch took: 0:00:30\n",
      "  Fakes correct discriminared: 16\n",
      "Saving the models...............................\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.794\n",
      "  Test Loss: 0.804\n",
      "  Test took: 0:00:10\n",
      "Improvement found: 0.794431 (previous best: 0.771327)\n",
      "\n",
      "======== Epoch 15 / 50 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss generetor: 0.679\n",
      "  Average training loss discriminator: 0.888\n",
      "  Training epoch took: 0:00:30\n",
      "  Fakes correct discriminared: 16\n",
      "Saving the models...............................\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.815\n",
      "  Test Loss: 0.755\n",
      "  Test took: 0:00:10\n",
      "Improvement found: 0.814573 (previous best: 0.794431)\n",
      "\n",
      "======== Epoch 16 / 50 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss generetor: 0.675\n",
      "  Average training loss discriminator: 0.903\n",
      "  Training epoch took: 0:00:30\n",
      "  Fakes correct discriminared: 16\n",
      "Saving the models...............................\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.847\n",
      "  Test Loss: 0.557\n",
      "  Test took: 0:00:10\n",
      "Improvement found: 0.846564 (previous best: 0.814573)\n",
      "\n",
      "======== Epoch 17 / 50 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss generetor: 0.699\n",
      "  Average training loss discriminator: 0.830\n",
      "  Training epoch took: 0:00:30\n",
      "  Fakes correct discriminared: 16\n",
      "Saving the models...............................\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.855\n",
      "  Test Loss: 0.546\n",
      "  Test took: 0:00:10\n",
      "Improvement found: 0.855450 (previous best: 0.846564)\n",
      "\n",
      "======== Epoch 18 / 50 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss generetor: 0.710\n",
      "  Average training loss discriminator: 0.872\n",
      "  Training epoch took: 0:00:30\n",
      "  Fakes correct discriminared: 16\n",
      "Saving the models...............................\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.792\n",
      "  Test Loss: 0.628\n",
      "  Test took: 0:00:11\n",
      "\n",
      "======== Epoch 19 / 50 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss generetor: 0.674\n",
      "  Average training loss discriminator: 0.808\n",
      "  Training epoch took: 0:00:30\n",
      "  Fakes correct discriminared: 16\n",
      "Saving the models...............................\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.727\n",
      "  Test Loss: 0.816\n",
      "  Test took: 0:00:10\n",
      "\n",
      "======== Epoch 20 / 50 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss generetor: 0.714\n",
      "  Average training loss discriminator: 0.914\n",
      "  Training epoch took: 0:00:30\n",
      "  Fakes correct discriminared: 16\n",
      "Saving the models...............................\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.742\n",
      "  Test Loss: 0.849\n",
      "  Test took: 0:00:10\n",
      "\n",
      "======== Epoch 21 / 50 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss generetor: 0.705\n",
      "  Average training loss discriminator: 0.877\n",
      "  Training epoch took: 0:00:30\n",
      "  Fakes correct discriminared: 16\n",
      "Saving the models...............................\n",
      "\n",
      "Running Test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.753\n",
      "  Test Loss: 0.847\n",
      "  Test took: 0:00:11\n",
      "\n",
      "======== Epoch 22 / 50 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss generetor: 0.645\n",
      "  Average training loss discriminator: 0.849\n",
      "  Training epoch took: 0:00:31\n",
      "  Fakes correct discriminared: 15\n",
      "Saving the models...............................\n",
      "\n",
      "Running Test...\n",
      "  Accuracy: 0.799\n",
      "  Test Loss: 0.823\n",
      "  Test took: 0:00:10\n",
      "Early stopping triggered after 5 epochs with no improvement.\n",
      "early stopping. Training Stopped\n"
     ]
    }
   ],
   "source": [
    "for epoch_i in range(0, num_train_epochs):\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, num_train_epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    tr_g_loss = 0\n",
    "    tr_d_loss = 0\n",
    "    true_fakes = 0\n",
    "\n",
    "    # Put the model into training mode.\n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "\n",
    "    for step, (text, input_mask, label, label_mask) in enumerate(train_dataloader):\n",
    "        # Progress update every print_each_n_step batches.\n",
    "        if step % print_each_n_step == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "\n",
    "        gen_samples = generate_fake()\n",
    "        encode_result = tokenizer.batch_encode_plus(gen_samples, add_special_tokens=True, max_length=seq_size, padding=\"max_length\", truncation=True, return_tensors='pt')\n",
    "        gen_rep = encode_result['input_ids'].to(device)\n",
    "        gen_att_mask = encode_result['attention_mask'].to(device)\n",
    "\n",
    "        \n",
    "        # Generate the output of the Discriminator for real and fake data.\n",
    "        # First, we put together the output of the tranformer and the generator\n",
    "        disciminator_input = torch.cat([text, gen_rep], dim=0)\n",
    "        # Also, join with the fake sentences mask\n",
    "\n",
    "        input_mask = torch.cat([input_mask, gen_att_mask], dim=0)\n",
    "        # Then, we select the output of the disciminator\n",
    "        features, logits, probs = discriminator(disciminator_input, input_mask)\n",
    "\n",
    "        # Finally, we separate the discriminator's output for the real and fake\n",
    "        # data\n",
    "        split_size = batch_size\n",
    "        features_list = torch.split(features, split_size)\n",
    "        # Splits the tensor into chunks. Each chunk is a view of the original tensor\n",
    "        D_real_features = features_list[0]\n",
    "        D_fake_features = features_list[1]\n",
    "\n",
    "        logits_list = torch.split(logits, split_size)\n",
    "        D_real_logits = logits_list[0]\n",
    "\n",
    "        probs_list = torch.split(probs, split_size)\n",
    "        D_real_probs = probs_list[0]\n",
    "        D_fake_probs = probs_list[1]\n",
    "\n",
    "        # Fake labels counting\n",
    "        true_fakes_batch = (torch.argmax(D_fake_probs, dim=1) == len(labels)).sum().item()\n",
    "        true_fakes += true_fakes_batch\n",
    "\n",
    "        # ---------------------------------\n",
    "        #  LOSS evaluation\n",
    "        # ---------------------------------\n",
    "        # Generator's LOSS estimation\n",
    "        g_loss_d = -1 * torch.mean(torch.log(1 - D_fake_probs[:, -1] + epsilon))\n",
    "        g_feat_reg = 0 * torch.mean(\n",
    "            torch.pow(torch.mean(D_real_features, dim=0) - torch.mean(D_fake_features, dim=0), 2)\n",
    "            )\n",
    "        g_loss = g_loss_d + g_feat_reg\n",
    "        # print(g_loss_d, g_feat_reg)\n",
    "\n",
    "        # Disciminator's LOSS estimation\n",
    "        logits = D_real_logits[:, 0:-1]\n",
    "        log_probs = F.log_softmax(logits, dim=-1)\n",
    "\n",
    "        # The discriminator provides an output for labeled and unlabeled real data\n",
    "        # so the loss evaluated for unlabeled data is ignored (masked)\n",
    "        label2one_hot = torch.nn.functional.one_hot(label, len(labels))\n",
    "        per_example_loss = -torch.sum(label2one_hot * log_probs, dim=-1)\n",
    "        per_example_loss = torch.masked_select(per_example_loss, label_mask)\n",
    "        labeled_example_count = per_example_loss.type(torch.float32).numel()\n",
    "\n",
    "        # It may be the case that a batch does not contain labeled examples,\n",
    "        # so the \"supervised loss\" in this case is not evaluated\n",
    "        if labeled_example_count == 0:\n",
    "            D_L_Supervised = 0\n",
    "        else:\n",
    "            D_L_Supervised = torch.div(torch.sum(per_example_loss.to(device)), labeled_example_count)\n",
    "\n",
    "        D_L_unsupervised1U = -1 * torch.mean(torch.log(1 - D_real_probs[:, -1] + epsilon))\n",
    "        D_L_unsupervised2U = -1 * torch.mean(torch.log(D_fake_probs[:, -1] + epsilon))\n",
    "        d_loss = D_L_Supervised + D_L_unsupervised1U + D_L_unsupervised2U\n",
    "        # print(D_L_Supervised, D_L_unsupervised1U, D_L_unsupervised2U)\n",
    "\n",
    "        # ---------------------------------\n",
    "        #  OPTIMIZATION\n",
    "        # ---------------------------------\n",
    "        # Avoid gradient accumulation\n",
    "        gen_optimizer.zero_grad()\n",
    "        dis_optimizer.zero_grad()\n",
    "\n",
    "        # Calculate weigth updates\n",
    "        # retain_graph=True is required since the underlying graph will be deleted after backward\n",
    "        g_loss.backward(retain_graph=True)\n",
    "        d_loss.backward(retain_graph=True)\n",
    "\n",
    "        # Apply modifications\n",
    "        gen_optimizer.step()\n",
    "        dis_optimizer.step()\n",
    "\n",
    "        # Save the losses to print them later\n",
    "        tr_g_loss += g_loss.item()\n",
    "        tr_d_loss += d_loss.item()\n",
    "\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss_g = tr_g_loss / len(train_dataloader)\n",
    "    avg_train_loss_d = tr_d_loss / len(train_dataloader)\n",
    "\n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss generetor: {0:.3f}\".format(avg_train_loss_g))\n",
    "    print(\"  Average training loss discriminator: {0:.3f}\".format(avg_train_loss_d))\n",
    "    print(\"  Training epoch took: {:}\".format(training_time))\n",
    "    print(\"  Fakes correct discriminared: {}\".format(true_fakes))\n",
    "\n",
    "    print(\"Saving the models...............................\")\n",
    "    # Saving the model\n",
    "    torch.save(generator, '../models/generator')\n",
    "    torch.save(discriminator, '../models/discriminator')\n",
    "\n",
    "    test_accuracy = test(\n",
    "        test_dataloader, epoch_i,\n",
    "        avg_train_loss_g, avg_train_loss_d, training_time, training_stats\n",
    "    )\n",
    "    training_stats[-1]['True fakes'] = true_fakes\n",
    "\n",
    "    # save_stats(training_stats, trial)\n",
    "\n",
    "    # check early stopping\n",
    "    early_stopping(test_accuracy)\n",
    "    if early_stopping.early_stop:\n",
    "        print('early stopping. Training Stopped')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mestrado",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
